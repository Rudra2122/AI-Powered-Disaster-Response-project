{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ac67be-ca4e-4027-ad4c-5bfe32db7b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /Users/rudrabrahmbhatt/Documents/AI_Powered_Disaster_Response_&_Resource_Allocation/disaster-ai/src/cv_dataset.py\n",
      "Classes: ['no-damage', 'minor-damage', 'major-damage', 'destroyed']\n"
     ]
    }
   ],
   "source": [
    "# point Python to your src folder and import the module\n",
    "import sys, importlib, os\n",
    "\n",
    "# adjust if your path is different\n",
    "SRC_DIR = \"disaster-ai/src\"\n",
    "assert os.path.exists(os.path.join(SRC_DIR, \"cv_dataset.py\")), \"cv_dataset.py not found under disaster-ai/src\"\n",
    "\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.append(SRC_DIR)\n",
    "\n",
    "import cv_dataset\n",
    "importlib.reload(cv_dataset)\n",
    "\n",
    "from cv_dataset import XBDDamageDataset, CLASSES, _find_label_path\n",
    "\n",
    "print(\"Loaded:\", cv_dataset.__file__)\n",
    "print(\"Classes:\", CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d009ce-cc59-41e0-821f-f18a3527edcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'torch.Tensor'> tensor(0)\n",
      "1 <class 'torch.Tensor'> tensor(0)\n",
      "2 <class 'torch.Tensor'> tensor(0)\n",
      "3 <class 'torch.Tensor'> tensor(0)\n",
      "4 <class 'torch.Tensor'> tensor(0)\n",
      "5 <class 'torch.Tensor'> tensor(0)\n",
      "6 <class 'torch.Tensor'> tensor(0)\n",
      "7 <class 'torch.Tensor'> tensor(0)\n",
      "8 <class 'torch.Tensor'> tensor(0)\n",
      "9 <class 'torch.Tensor'> tensor(0)\n",
      "10 <class 'torch.Tensor'> tensor(0)\n",
      "11 <class 'torch.Tensor'> tensor(0)\n",
      "12 <class 'torch.Tensor'> tensor(0)\n",
      "13 <class 'torch.Tensor'> tensor(0)\n",
      "14 <class 'torch.Tensor'> tensor(0)\n",
      "15 <class 'torch.Tensor'> tensor(0)\n",
      "16 <class 'torch.Tensor'> tensor(0)\n",
      "17 <class 'torch.Tensor'> tensor(0)\n",
      "18 <class 'torch.Tensor'> tensor(0)\n",
      "19 <class 'torch.Tensor'> tensor(0)\n",
      "20 <class 'torch.Tensor'> tensor(0)\n",
      "21 <class 'torch.Tensor'> tensor(0)\n",
      "22 <class 'torch.Tensor'> tensor(0)\n",
      "23 <class 'torch.Tensor'> tensor(0)\n",
      "24 <class 'torch.Tensor'> tensor(0)\n",
      "25 <class 'torch.Tensor'> tensor(0)\n",
      "26 <class 'torch.Tensor'> tensor(0)\n",
      "27 <class 'torch.Tensor'> tensor(0)\n",
      "28 <class 'torch.Tensor'> tensor(0)\n",
      "29 <class 'torch.Tensor'> tensor(0)\n",
      "30 <class 'torch.Tensor'> tensor(0)\n",
      "31 <class 'torch.Tensor'> tensor(0)\n",
      "32 <class 'torch.Tensor'> tensor(0)\n",
      "33 <class 'torch.Tensor'> tensor(0)\n",
      "34 <class 'torch.Tensor'> tensor(0)\n",
      "35 <class 'torch.Tensor'> tensor(0)\n",
      "36 <class 'torch.Tensor'> tensor(0)\n",
      "37 <class 'torch.Tensor'> tensor(0)\n",
      "38 <class 'torch.Tensor'> tensor(0)\n",
      "39 <class 'torch.Tensor'> tensor(0)\n",
      "Unique labels seen: {0}\n"
     ]
    }
   ],
   "source": [
    "# Probe 1: print first 40 raw labels to see variety\n",
    "for i in range(40):\n",
    "    _, y = ds_tr_full[i]   # NOTE: use the *full* train dataset, not the subset\n",
    "    print(i, type(y), y)\n",
    "\n",
    "# Probe 2: unique labels across a wider slice\n",
    "uniq = set()\n",
    "for i in range(min(5000, len(ds_tr_full))):\n",
    "    _, y = ds_tr_full[i]\n",
    "    try:\n",
    "        uniq.add(int(y))\n",
    "    except Exception:\n",
    "        uniq.add(y)\n",
    "print(\"Unique labels seen:\", uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "621b8302-f7f2-49ec-bca0-b43aefb2f8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <built-in method size of Tensor object at 0x16802cb40> tensor(0)\n",
      "1 <built-in method size of Tensor object at 0x1692e4dc0> tensor(0)\n",
      "2 <built-in method size of Tensor object at 0x16802cb40> tensor(0)\n",
      "3 <built-in method size of Tensor object at 0x1692e5ef0> tensor(0)\n",
      "4 <built-in method size of Tensor object at 0x16802cb40> tensor(0)\n",
      "5 <built-in method size of Tensor object at 0x1692e4370> tensor(0)\n",
      "6 <built-in method size of Tensor object at 0x16802cb40> tensor(0)\n",
      "7 <built-in method size of Tensor object at 0x1692e5ae0> tensor(0)\n",
      "8 <built-in method size of Tensor object at 0x16802cb40> tensor(0)\n",
      "9 <built-in method size of Tensor object at 0x1692e6490> tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# Peek a few samples to inspect the file path and label\n",
    "for i in range(10):\n",
    "    x, y = ds_tr_full[i]\n",
    "    print(i, getattr(getattr(x, 'size', None), '__repr__', lambda: '?')(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "953e89ea-d278-40c1-963c-ff81cfdfbe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1792 → disaster-ai/data/xbd/tier1/train.jsonl\n",
      "Wrote 448   → disaster-ai/data/xbd/tier1/val.jsonl\n",
      "Train class counts (raw): {'no-damage': 1042, 'minor-damage': 166, 'major-damage': 247, 'destroyed': 337}\n",
      "Val   class counts (raw): {'no-damage': 261, 'minor-damage': 42, 'major-damage': 61, 'destroyed': 84}\n",
      "[train.jsonl] kept 1792 / 1792\n",
      "Class counts: {'no-damage': 1042, 'minor-damage': 166, 'major-damage': 247, 'destroyed': 337}\n",
      "[val.jsonl] kept 448 / 448\n",
      "Class counts: {'no-damage': 261, 'minor-damage': 42, 'major-damage': 61, 'destroyed': 84}\n",
      "Train class counts (balanced): {'no-damage': 500, 'minor-damage': 166, 'major-damage': 247, 'destroyed': 337}\n",
      "Val   class counts (balanced): {'no-damage': 261, 'minor-damage': 42, 'major-damage': 61, 'destroyed': 84}\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "import os, json, re, random, glob, csv\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "\n",
    "DATA_DIR = \"disaster-ai/data/xbd/tier1\"   # <-- point this to your tier1 folder\n",
    "SEED = 42\n",
    "CLASSES = ['no-damage','minor-damage','major-damage','destroyed']\n",
    "CLASS_TO_ID = {c:i for i,c in enumerate(CLASSES)}\n",
    "IMG_EXTS = (\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\")\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "# --- STEP 1: make train.jsonl & val.jsonl from per-image JSONs in labels/ ---\n",
    "labels_dir = os.path.join(DATA_DIR, \"labels\")\n",
    "images_dir = os.path.join(DATA_DIR, \"images\")\n",
    "out_train = os.path.join(DATA_DIR, \"train.jsonl\")\n",
    "out_val   = os.path.join(DATA_DIR, \"val.jsonl\")\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def find_damage_anywhere(obj):\n",
    "    \"\"\"\n",
    "    Recursively search for a string value equal to one of the class names\n",
    "    under common keys like 'damage', 'damage_status', 'label', 'class', etc.\n",
    "    Returns normalized label or None.\n",
    "    \"\"\"\n",
    "    stack = [obj]\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        if isinstance(cur, dict):\n",
    "            for k, v in cur.items():\n",
    "                if isinstance(v, str):\n",
    "                    s = re.sub(r'\\s+', '-', v.strip().lower())\n",
    "                    if s in CLASS_TO_ID:\n",
    "                        return s\n",
    "                elif isinstance(v, (dict, list)):\n",
    "                    stack.append(v)\n",
    "        elif isinstance(cur, list):\n",
    "            stack.extend(cur)\n",
    "    return None\n",
    "\n",
    "def build_index(split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Scans labels/*.json, matches to images/*.png|jpg, keeps only *_post_disaster.*\n",
    "    Returns two lists of dicts: [{image_path, damage}, ...] for train/val.\n",
    "    \"\"\"\n",
    "    label_files = sorted(glob.glob(os.path.join(labels_dir, \"*.json\")))\n",
    "    records = []\n",
    "\n",
    "    for jpath in label_files:\n",
    "        fname = os.path.basename(jpath)             # e.g., \"socal-fire_00001396_post_disaster.json\"\n",
    "        base = os.path.splitext(fname)[0]           # socal-fire_00001396_post_disaster\n",
    "        # prefer post_disaster only for damage classification\n",
    "        if \"_post_disaster\" not in base:\n",
    "            continue\n",
    "\n",
    "        dmg = find_damage_anywhere(read_json(jpath))\n",
    "        if dmg is None:\n",
    "            # skip unknown / unlabeled samples\n",
    "            continue\n",
    "\n",
    "        # image path candidates\n",
    "        for ext in IMG_EXTS:\n",
    "            ipath = os.path.join(images_dir, base + ext)\n",
    "            if os.path.isfile(ipath):\n",
    "                records.append({\"image_path\": os.path.relpath(ipath, DATA_DIR),\n",
    "                                \"damage\": dmg})\n",
    "                break\n",
    "        # if not found, try some common alternative filenames (some sets add suffixes)\n",
    "        # (add more heuristics here if needed)\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"No labeled post_disaster samples found. Check DATA_DIR paths.\")\n",
    "\n",
    "    # shuffle & split\n",
    "    random.shuffle(records)\n",
    "    n_train = int(len(records) * split_ratio)\n",
    "    train_recs = records[:n_train]\n",
    "    val_recs   = records[n_train:]\n",
    "    return train_recs, val_recs\n",
    "\n",
    "train_recs, val_recs = build_index(split_ratio=0.8)\n",
    "\n",
    "def write_jsonl(path, rows):\n",
    "    with open(path, \"w\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r) + \"\\n\")\n",
    "\n",
    "write_jsonl(out_train, train_recs)\n",
    "write_jsonl(out_val,   val_recs)\n",
    "\n",
    "print(f\"Wrote {len(train_recs)} → {out_train}\")\n",
    "print(f\"Wrote {len(val_recs)}   → {out_val}\")\n",
    "\n",
    "# quick distribution check\n",
    "def counts(rows):\n",
    "    c = {k:0 for k in CLASSES}\n",
    "    for r in rows: c[r[\"damage\"]] += 1\n",
    "    return c\n",
    "print(\"Train class counts (raw):\", counts(train_recs))\n",
    "print(\"Val   class counts (raw):\", counts(val_recs))\n",
    "\n",
    "# --- STEP 2: dataset for JSONL annotations ---\n",
    "def _norm_label(s): return re.sub(r'\\s+', '-', s.strip().lower())\n",
    "\n",
    "class LabeledImages(Dataset):\n",
    "    def __init__(self, ann_file, root, transform=None, exts=IMG_EXTS, verbose=True):\n",
    "        self.root = root\n",
    "        self.tf = transform\n",
    "        self.exts = tuple(e.lower() for e in exts)\n",
    "        self.items = []\n",
    "        n_total = 0\n",
    "        with open(ann_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                n_total += 1\n",
    "                obj = json.loads(line)\n",
    "                p = obj[\"image_path\"]\n",
    "                lab = _norm_label(obj[\"damage\"])\n",
    "                if lab not in CLASS_TO_ID:\n",
    "                    continue\n",
    "                ipath = p if os.path.isabs(p) else os.path.join(root, p)\n",
    "                if not os.path.isfile(ipath):\n",
    "                    continue\n",
    "                self.items.append((ipath, CLASS_TO_ID[lab]))\n",
    "        if verbose:\n",
    "            print(f\"[{os.path.basename(ann_file)}] kept {len(self.items)} / {n_total}\")\n",
    "            cnt = torch.zeros(len(CLASSES), dtype=torch.long)\n",
    "            for _, y in self.items: cnt[y] += 1\n",
    "            print(\"Class counts:\", dict(zip(CLASSES, cnt.tolist())))\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self, i):\n",
    "        p, y = self.items[i]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.tf: img = self.tf(img)\n",
    "        return img, y\n",
    "\n",
    "# --- STEP 3: build balanced (stratified) subsets ---\n",
    "def build_stratified_subset(dataset, limit=None, seed=SEED):\n",
    "    rng = random.Random(seed)\n",
    "    idx_by_class = {c: [] for c in range(len(CLASSES))}\n",
    "    for i in range(len(dataset)):\n",
    "        _, y = dataset[i]\n",
    "        idx_by_class[int(y)].append(i)\n",
    "    empty = [CLASSES[c] for c, lst in idx_by_class.items() if len(lst) == 0]\n",
    "    if empty:\n",
    "        raise RuntimeError(f\"No samples for classes: {empty}. Re-check labels parsing.\")\n",
    "    if limit is None:\n",
    "        per = min(len(v) for v in idx_by_class.values())\n",
    "        tgt = {c: per for c in idx_by_class}\n",
    "    else:\n",
    "        k = len(CLASSES); base = limit // k; rem = limit % k\n",
    "        tgt = {c: base + (1 if c < rem else 0) for c in range(k)}\n",
    "    chosen = []\n",
    "    for c, pool in idx_by_class.items():\n",
    "        rng.shuffle(pool)\n",
    "        chosen.extend(pool[:min(tgt[c], len(pool))])\n",
    "    rng.shuffle(chosen)\n",
    "    return Subset(dataset, chosen)\n",
    "\n",
    "# instantiate datasets using the JSONLs we just created\n",
    "ds_tr_full = LabeledImages(out_train, DATA_DIR, transform=None, verbose=True)\n",
    "ds_va_full = LabeledImages(out_val,   DATA_DIR, transform=None, verbose=True)\n",
    "\n",
    "# choose sizes that fit your GPU/time budget\n",
    "ds_tr = build_stratified_subset(ds_tr_full, limit=2000, seed=SEED)\n",
    "ds_va = build_stratified_subset(ds_va_full, limit=1600, seed=SEED)\n",
    "\n",
    "# sanity check\n",
    "def class_counts(ds):\n",
    "    cnt = torch.zeros(len(CLASSES), dtype=torch.long)\n",
    "    for i in range(len(ds)):\n",
    "        _, y = ds[i]; cnt[int(y)] += 1\n",
    "    return dict(zip(CLASSES, cnt.tolist()))\n",
    "\n",
    "print(\"Train class counts (balanced):\", class_counts(ds_tr))\n",
    "print(\"Val   class counts (balanced):\", class_counts(ds_va))\n",
    "\n",
    "# --- STEP 4: build DataLoaders ---\n",
    "train_dl = DataLoader(ds_tr, batch_size=64, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_dl   = DataLoader(ds_va, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d14dc939-9b7c-4338-9e8e-eab21c5535a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1792 → disaster-ai/data/xbd/tier1/train.jsonl\n",
      "Wrote 448   → disaster-ai/data/xbd/tier1/val.jsonl\n",
      "Train class counts (raw): {'no-damage': 1042, 'minor-damage': 166, 'major-damage': 247, 'destroyed': 337}\n",
      "Val   class counts (raw): {'no-damage': 261, 'minor-damage': 42, 'major-damage': 61, 'destroyed': 84}\n",
      "[train.jsonl] kept 1792 / 1792\n",
      "Class counts: {'no-damage': 1042, 'minor-damage': 166, 'major-damage': 247, 'destroyed': 337}\n",
      "[val.jsonl] kept 448 / 448\n",
      "Class counts: {'no-damage': 261, 'minor-damage': 42, 'major-damage': 61, 'destroyed': 84}\n",
      "Train class counts (balanced): {'no-damage': 500, 'minor-damage': 166, 'major-damage': 247, 'destroyed': 337}\n",
      "Val   class counts (balanced): {'no-damage': 261, 'minor-damage': 42, 'major-damage': 61, 'destroyed': 84}\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "import os, json, re, random, glob, csv\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "\n",
    "DATA_DIR = \"disaster-ai/data/xbd/tier1\"   # <-- point this to your tier1 folder\n",
    "SEED = 42\n",
    "CLASSES = ['no-damage','minor-damage','major-damage','destroyed']\n",
    "CLASS_TO_ID = {c:i for i,c in enumerate(CLASSES)}\n",
    "IMG_EXTS = (\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\")\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "# --- STEP 1: make train.jsonl & val.jsonl from per-image JSONs in labels/ ---\n",
    "labels_dir = os.path.join(DATA_DIR, \"labels\")\n",
    "images_dir = os.path.join(DATA_DIR, \"images\")\n",
    "out_train = os.path.join(DATA_DIR, \"train.jsonl\")\n",
    "out_val   = os.path.join(DATA_DIR, \"val.jsonl\")\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def find_damage_anywhere(obj):\n",
    "    \"\"\"\n",
    "    Recursively search for a string value equal to one of the class names\n",
    "    under common keys like 'damage', 'damage_status', 'label', 'class', etc.\n",
    "    Returns normalized label or None.\n",
    "    \"\"\"\n",
    "    stack = [obj]\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        if isinstance(cur, dict):\n",
    "            for k, v in cur.items():\n",
    "                if isinstance(v, str):\n",
    "                    s = re.sub(r'\\s+', '-', v.strip().lower())\n",
    "                    if s in CLASS_TO_ID:\n",
    "                        return s\n",
    "                elif isinstance(v, (dict, list)):\n",
    "                    stack.append(v)\n",
    "        elif isinstance(cur, list):\n",
    "            stack.extend(cur)\n",
    "    return None\n",
    "\n",
    "def build_index(split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Scans labels/*.json, matches to images/*.png|jpg, keeps only *_post_disaster.*\n",
    "    Returns two lists of dicts: [{image_path, damage}, ...] for train/val.\n",
    "    \"\"\"\n",
    "    label_files = sorted(glob.glob(os.path.join(labels_dir, \"*.json\")))\n",
    "    records = []\n",
    "\n",
    "    for jpath in label_files:\n",
    "        fname = os.path.basename(jpath)             # e.g., \"socal-fire_00001396_post_disaster.json\"\n",
    "        base = os.path.splitext(fname)[0]           # socal-fire_00001396_post_disaster\n",
    "        # prefer post_disaster only for damage classification\n",
    "        if \"_post_disaster\" not in base:\n",
    "            continue\n",
    "\n",
    "        dmg = find_damage_anywhere(read_json(jpath))\n",
    "        if dmg is None:\n",
    "            # skip unknown / unlabeled samples\n",
    "            continue\n",
    "\n",
    "        # image path candidates\n",
    "        for ext in IMG_EXTS:\n",
    "            ipath = os.path.join(images_dir, base + ext)\n",
    "            if os.path.isfile(ipath):\n",
    "                records.append({\"image_path\": os.path.relpath(ipath, DATA_DIR),\n",
    "                                \"damage\": dmg})\n",
    "                break\n",
    "        # if not found, try some common alternative filenames (some sets add suffixes)\n",
    "        # (add more heuristics here if needed)\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"No labeled post_disaster samples found. Check DATA_DIR paths.\")\n",
    "\n",
    "    # shuffle & split\n",
    "    random.shuffle(records)\n",
    "    n_train = int(len(records) * split_ratio)\n",
    "    train_recs = records[:n_train]\n",
    "    val_recs   = records[n_train:]\n",
    "    return train_recs, val_recs\n",
    "\n",
    "train_recs, val_recs = build_index(split_ratio=0.8)\n",
    "\n",
    "def write_jsonl(path, rows):\n",
    "    with open(path, \"w\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r) + \"\\n\")\n",
    "\n",
    "write_jsonl(out_train, train_recs)\n",
    "write_jsonl(out_val,   val_recs)\n",
    "\n",
    "print(f\"Wrote {len(train_recs)} → {out_train}\")\n",
    "print(f\"Wrote {len(val_recs)}   → {out_val}\")\n",
    "\n",
    "# quick distribution check\n",
    "def counts(rows):\n",
    "    c = {k:0 for k in CLASSES}\n",
    "    for r in rows: c[r[\"damage\"]] += 1\n",
    "    return c\n",
    "print(\"Train class counts (raw):\", counts(train_recs))\n",
    "print(\"Val   class counts (raw):\", counts(val_recs))\n",
    "\n",
    "# --- STEP 2: dataset for JSONL annotations ---\n",
    "def _norm_label(s): return re.sub(r'\\s+', '-', s.strip().lower())\n",
    "\n",
    "class LabeledImages(Dataset):\n",
    "    def __init__(self, ann_file, root, transform=None, exts=IMG_EXTS, verbose=True):\n",
    "        self.root = root\n",
    "        self.tf = transform\n",
    "        self.exts = tuple(e.lower() for e in exts)\n",
    "        self.items = []\n",
    "        n_total = 0\n",
    "        with open(ann_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                n_total += 1\n",
    "                obj = json.loads(line)\n",
    "                p = obj[\"image_path\"]\n",
    "                lab = _norm_label(obj[\"damage\"])\n",
    "                if lab not in CLASS_TO_ID:\n",
    "                    continue\n",
    "                ipath = p if os.path.isabs(p) else os.path.join(root, p)\n",
    "                if not os.path.isfile(ipath):\n",
    "                    continue\n",
    "                self.items.append((ipath, CLASS_TO_ID[lab]))\n",
    "        if verbose:\n",
    "            print(f\"[{os.path.basename(ann_file)}] kept {len(self.items)} / {n_total}\")\n",
    "            cnt = torch.zeros(len(CLASSES), dtype=torch.long)\n",
    "            for _, y in self.items: cnt[y] += 1\n",
    "            print(\"Class counts:\", dict(zip(CLASSES, cnt.tolist())))\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self, i):\n",
    "        p, y = self.items[i]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.tf: img = self.tf(img)\n",
    "        return img, y\n",
    "\n",
    "# --- STEP 3: build balanced (stratified) subsets ---\n",
    "def build_stratified_subset(dataset, limit=None, seed=SEED):\n",
    "    rng = random.Random(seed)\n",
    "    idx_by_class = {c: [] for c in range(len(CLASSES))}\n",
    "    for i in range(len(dataset)):\n",
    "        _, y = dataset[i]\n",
    "        idx_by_class[int(y)].append(i)\n",
    "    empty = [CLASSES[c] for c, lst in idx_by_class.items() if len(lst) == 0]\n",
    "    if empty:\n",
    "        raise RuntimeError(f\"No samples for classes: {empty}. Re-check labels parsing.\")\n",
    "    if limit is None:\n",
    "        per = min(len(v) for v in idx_by_class.values())\n",
    "        tgt = {c: per for c in idx_by_class}\n",
    "    else:\n",
    "        k = len(CLASSES); base = limit // k; rem = limit % k\n",
    "        tgt = {c: base + (1 if c < rem else 0) for c in range(k)}\n",
    "    chosen = []\n",
    "    for c, pool in idx_by_class.items():\n",
    "        rng.shuffle(pool)\n",
    "        chosen.extend(pool[:min(tgt[c], len(pool))])\n",
    "    rng.shuffle(chosen)\n",
    "    return Subset(dataset, chosen)\n",
    "\n",
    "# instantiate datasets using the JSONLs we just created\n",
    "ds_tr_full = LabeledImages(out_train, DATA_DIR, transform=None, verbose=True)\n",
    "ds_va_full = LabeledImages(out_val,   DATA_DIR, transform=None, verbose=True)\n",
    "\n",
    "# choose sizes that fit your GPU/time budget\n",
    "ds_tr = build_stratified_subset(ds_tr_full, limit=2000, seed=SEED)\n",
    "ds_va = build_stratified_subset(ds_va_full, limit=1600, seed=SEED)\n",
    "\n",
    "# sanity check\n",
    "def class_counts(ds):\n",
    "    cnt = torch.zeros(len(CLASSES), dtype=torch.long)\n",
    "    for i in range(len(ds)):\n",
    "        _, y = ds[i]; cnt[int(y)] += 1\n",
    "    return dict(zip(CLASSES, cnt.tolist()))\n",
    "\n",
    "print(\"Train class counts (balanced):\", class_counts(ds_tr))\n",
    "print(\"Val   class counts (balanced):\", class_counts(ds_va))\n",
    "\n",
    "# --- STEP 4: build DataLoaders ---\n",
    "train_dl = DataLoader(ds_tr, batch_size=64, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_dl   = DataLoader(ds_va, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38690b43-368b-41c1-a4f2-a0a77796c006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5.A — imports & config\n",
    "import sys, os, json, math, time, importlib\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"disaster-ai/src\")   # point Python to your src folder\n",
    "\n",
    "import cv_dataset; importlib.reload(cv_dataset)\n",
    "from cv_dataset import XBDDamageDataset, CLASSES\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR  = \"disaster-ai/data/xbd/tier1\"     # or \".../train\"\n",
    "IMG_SIZE  = 256\n",
    "BATCH_TR  = 64\n",
    "BATCH_VA  = 128\n",
    "SEED      = 42\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      else \"mps\" if torch.backends.mps.is_available()\n",
    "                      else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f9e6cae-4d7e-4bef-b141-6cf86e63166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1792 → disaster-ai/data/xbd/tier1/train.jsonl\n",
      "Wrote 448 → disaster-ai/data/xbd/tier1/val.jsonl\n",
      "Train class counts (raw): {'no-damage': 1042, 'minor-damage': 166, 'major-damage': 247, 'destroyed': 337}\n",
      "Val   class counts (raw): {'no-damage': 261, 'minor-damage': 42, 'major-damage': 61, 'destroyed': 84}\n",
      "[train.jsonl] kept 1792 / 1792\n",
      "Class counts: {'no-damage': 1042, 'minor-damage': 166, 'major-damage': 247, 'destroyed': 337}\n",
      "[val.jsonl] kept 448 / 448\n",
      "Class counts: {'no-damage': 261, 'minor-damage': 42, 'major-damage': 61, 'destroyed': 84}\n",
      "Train class counts (balanced): {'no-damage': 500, 'minor-damage': 166, 'major-damage': 247, 'destroyed': 337}\n",
      "Val   class counts (balanced): {'no-damage': 261, 'minor-damage': 42, 'major-damage': 61, 'destroyed': 84}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.], device='mps:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Step 5.B (replacement) — use JSONL + stratified subsets so every class is present ===\n",
    "import os, re, json, glob, random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Reuse the same globals from Step 5.A\n",
    "# DATA_DIR, CLASSES, SEED, IMG_SIZE, BATCH_TR, BATCH_VA already defined\n",
    "\n",
    "random.seed(SEED)\n",
    "CLASS_TO_ID = {c:i for i,c in enumerate(CLASSES)}\n",
    "IMG_EXTS = (\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\")\n",
    "\n",
    "labels_dir = os.path.join(DATA_DIR, \"labels\")\n",
    "images_dir = os.path.join(DATA_DIR, \"images\")\n",
    "out_train = os.path.join(DATA_DIR, \"train.jsonl\")\n",
    "out_val   = os.path.join(DATA_DIR, \"val.jsonl\")\n",
    "\n",
    "def _norm_label(s): \n",
    "    return re.sub(r\"\\s+\", \"-\", s.strip().lower())\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def find_damage_anywhere(obj):\n",
    "    \"\"\"Find any string in the nested dict/list that matches a class name.\"\"\"\n",
    "    stack = [obj]\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        if isinstance(cur, dict):\n",
    "            for _, v in cur.items():\n",
    "                if isinstance(v, str):\n",
    "                    s = _norm_label(v)\n",
    "                    if s in CLASS_TO_ID:\n",
    "                        return s\n",
    "                elif isinstance(v, (dict, list)):\n",
    "                    stack.append(v)\n",
    "        elif isinstance(cur, list):\n",
    "            stack.extend(cur)\n",
    "    return None\n",
    "\n",
    "def build_index(split_ratio=0.8):\n",
    "    \"\"\"Scan labels/*.json, keep *_post_disaster only, match to images/, return train/val lists.\"\"\"\n",
    "    label_files = sorted(glob.glob(os.path.join(labels_dir, \"*.json\")))\n",
    "    records = []\n",
    "    for jpath in label_files:\n",
    "        base = os.path.splitext(os.path.basename(jpath))[0]\n",
    "        if \"_post_disaster\" not in base:\n",
    "            continue\n",
    "        dmg = find_damage_anywhere(read_json(jpath))\n",
    "        if dmg is None:\n",
    "            continue\n",
    "        # find the image (try common extensions)\n",
    "        ipath = None\n",
    "        for ext in IMG_EXTS:\n",
    "            cand = os.path.join(images_dir, base + ext)\n",
    "            if os.path.isfile(cand):\n",
    "                ipath = cand; break\n",
    "        if ipath is None: \n",
    "            continue\n",
    "        records.append({\"image_path\": os.path.relpath(ipath, DATA_DIR), \"damage\": dmg})\n",
    "    if not records:\n",
    "        raise RuntimeError(\"No labeled post_disaster samples found. Check DATA_DIR paths.\")\n",
    "    random.shuffle(records)\n",
    "    n_tr = int(len(records) * split_ratio)\n",
    "    return records[:n_tr], records[n_tr:]\n",
    "\n",
    "def write_jsonl(path, rows):\n",
    "    with open(path, \"w\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r) + \"\\n\")\n",
    "\n",
    "# Build/refresh JSONLs (idempotent; fast)\n",
    "tr_rows, va_rows = build_index(split_ratio=0.8)\n",
    "write_jsonl(out_train, tr_rows)\n",
    "write_jsonl(out_val,   va_rows)\n",
    "print(f\"Wrote {len(tr_rows)} → {out_train}\")\n",
    "print(f\"Wrote {len(va_rows)} → {out_val}\")\n",
    "\n",
    "def counts(rows):\n",
    "    c = {k:0 for k in CLASSES}\n",
    "    for r in rows: c[_norm_label(r[\"damage\"])] += 1\n",
    "    return c\n",
    "print(\"Train class counts (raw):\", counts(tr_rows))\n",
    "print(\"Val   class counts (raw):\", counts(va_rows))\n",
    "\n",
    "# ----- Dataset that reads from JSONL -----\n",
    "class LabeledImages(Dataset):\n",
    "    def __init__(self, ann_file, root, transform=None, exts=IMG_EXTS, verbose=True):\n",
    "        self.root = root\n",
    "        self.tf   = transform\n",
    "        self.exts = tuple(e.lower() for e in exts)\n",
    "        self.items = []\n",
    "        n_total = 0\n",
    "        with open(ann_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                n_total += 1\n",
    "                obj = json.loads(line)\n",
    "                p   = obj[\"image_path\"]\n",
    "                lab = _norm_label(obj[\"damage\"])\n",
    "                if lab not in CLASS_TO_ID: \n",
    "                    continue\n",
    "                ipath = p if os.path.isabs(p) else os.path.join(root, p)\n",
    "                if not os.path.isfile(ipath): \n",
    "                    continue\n",
    "                self.items.append((ipath, CLASS_TO_ID[lab]))\n",
    "        if verbose:\n",
    "            print(f\"[{Path(ann_file).name}] kept {len(self.items)} / {n_total}\")\n",
    "            cnt = torch.zeros(len(CLASSES), dtype=torch.long)\n",
    "            for _, y in self.items: cnt[y] += 1\n",
    "            print(\"Class counts:\", dict(zip(CLASSES, cnt.tolist())))\n",
    "\n",
    "    def __len__(self):  return len(self.items)\n",
    "    def __getitem__(self, i):\n",
    "        p, y = self.items[i]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.tf: img = self.tf(img)\n",
    "        return img, y\n",
    "\n",
    "# ----- Balanced subset builder -----\n",
    "def build_stratified_subset(dataset, limit=None, seed=SEED):\n",
    "    rng = random.Random(seed)\n",
    "    idx_by_class = {c: [] for c in range(len(CLASSES))}\n",
    "    for i in range(len(dataset)):\n",
    "        _, y = dataset[i]\n",
    "        idx_by_class[int(y)].append(i)\n",
    "    missing = [CLASSES[c] for c,lst in idx_by_class.items() if len(lst)==0]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"No samples for classes: {missing}. Fix label parsing first.\")\n",
    "    if limit is None:\n",
    "        per = min(len(v) for v in idx_by_class.values())\n",
    "        tgt = {c: per for c in idx_by_class}\n",
    "    else:\n",
    "        k = len(CLASSES); base = limit // k; rem = limit % k\n",
    "        tgt = {c: base + (1 if c < rem else 0) for c in range(k)}\n",
    "    chosen = []\n",
    "    for c, pool in idx_by_class.items():\n",
    "        rng.shuffle(pool)\n",
    "        chosen.extend(pool[:min(tgt[c], len(pool))])\n",
    "    rng.shuffle(chosen)\n",
    "    return Subset(dataset, chosen)\n",
    "\n",
    "# ----- Transforms (same normalization used everywhere) -----\n",
    "tf_train = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "tf_eval  = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# ----- Instantiate datasets + BALANCED subsets -----\n",
    "ds_tr_full = LabeledImages(out_train, DATA_DIR, transform=tf_train, verbose=True)\n",
    "ds_va_full = LabeledImages(out_val,   DATA_DIR, transform=tf_eval,  verbose=True)\n",
    "\n",
    "# Choose sizes that fit your GPU/time budget; these are examples:\n",
    "ds_tr = build_stratified_subset(ds_tr_full, limit=2000, seed=SEED)\n",
    "ds_va = build_stratified_subset(ds_va_full, limit=1600, seed=SEED)\n",
    "\n",
    "def class_counts(ds):\n",
    "    cnt = torch.zeros(len(CLASSES), dtype=torch.long)\n",
    "    for i in range(len(ds)):\n",
    "        _, y = ds[i]; cnt[int(y)] += 1\n",
    "    return dict(zip(CLASSES, cnt.tolist()))\n",
    "\n",
    "print(\"Train class counts (balanced):\", class_counts(ds_tr))\n",
    "print(\"Val   class counts (balanced):\", class_counts(ds_va))\n",
    "\n",
    "# ----- Dataloaders -----\n",
    "train_dl = DataLoader(ds_tr, batch_size=BATCH_TR, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_dl   = DataLoader(ds_va, batch_size=BATCH_VA, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# For the CE loss, weights can be uniform since the subset is balanced:\n",
    "ce_weights = torch.ones(len(CLASSES), dtype=torch.float, device=device)\n",
    "ce_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "024b04b9-c660-4948-a7d2-ab7055e06b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts in ds_tr: {'no-damage': 500.0, 'minor-damage': 166.0, 'major-damage': 247.0, 'destroyed': 337.0}\n",
      "Class weights: [0.5319135785102844, 1.602149248123169, 1.076748013496399, 0.7891892194747925]\n"
     ]
    }
   ],
   "source": [
    "def subset_counts(subset):\n",
    "    cnt = torch.zeros(len(CLASSES), dtype=torch.long)\n",
    "    for i in range(len(subset)):\n",
    "        _, y = subset[i]\n",
    "        cnt[int(y)] += 1\n",
    "    return cnt\n",
    "\n",
    "cnt_tr = subset_counts(ds_tr).float()\n",
    "print(\"Counts in ds_tr:\", dict(zip(CLASSES, cnt_tr.tolist())))\n",
    "\n",
    "# inverse-frequency weights, normalized to mean=1\n",
    "weights = (cnt_tr.sum() / cnt_tr).clamp(max=10.0)   # avoid huge weights if a class is tiny\n",
    "weights = weights / weights.mean()\n",
    "print(\"Class weights:\", weights.tolist())\n",
    "\n",
    "ce_weights = weights.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=ce_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0abeb78-aa04-4d4f-aa4a-3106f56fc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5.C — model & optim\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(CLASSES))\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "criterion = nn.CrossEntropyLoss(weight=ce_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6094fd25-6c91-46fb-8d77-bdc6a5aaa9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded OK, samples seen: 512\n"
     ]
    }
   ],
   "source": [
    "# --- SAFE DATASET + DATALOADERS (drop-in) ---\n",
    "import os, json, re, random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "# 1) allow PIL to read truncated files instead of crashing workers\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# If these are already defined earlier in your notebook, this keeps them in sync\n",
    "try:\n",
    "    CLASSES\n",
    "except NameError:\n",
    "    CLASSES = ['no-damage','minor-damage','major-damage','destroyed']\n",
    "CLASS_TO_ID = {c:i for i,c in enumerate(CLASSES)}\n",
    "\n",
    "# If you already set these earlier, this block will just reuse them\n",
    "try:\n",
    "    DATA_DIR\n",
    "except NameError:\n",
    "    DATA_DIR = \"disaster-ai/data/xbd/tier1\"   # <= adjust if needed\n",
    "\n",
    "# -----------------------\n",
    "# Safe collate: drops None samples returned by dataset\n",
    "# -----------------------\n",
    "def safe_collate(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if len(batch) == 0:\n",
    "        return torch.empty(0), torch.empty(0, dtype=torch.long)\n",
    "    return default_collate(batch)\n",
    "\n",
    "# -----------------------\n",
    "# Safe dataset: returns None on any load/transform error\n",
    "# -----------------------\n",
    "def _norm_label(s): \n",
    "    return re.sub(r'\\s+', '-', s.strip().lower())\n",
    "\n",
    "class LabeledImagesSafe(Dataset):\n",
    "    def __init__(self, ann_file, root, transform=None, verbose=True):\n",
    "        self.root = root\n",
    "        self.tf = transform\n",
    "        self.items = []\n",
    "        n_total = 0\n",
    "        with open(ann_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                n_total += 1\n",
    "                obj = json.loads(line)\n",
    "                p_rel = obj[\"image_path\"]\n",
    "                lab = _norm_label(obj[\"damage\"])\n",
    "                if lab not in CLASS_TO_ID:\n",
    "                    continue\n",
    "                p_abs = p_rel if os.path.isabs(p_rel) else os.path.join(root, p_rel)\n",
    "                if not os.path.isfile(p_abs):\n",
    "                    continue\n",
    "                self.items.append((p_abs, CLASS_TO_ID[lab]))\n",
    "        if verbose:\n",
    "            print(f\"[{os.path.basename(ann_file)}] kept {len(self.items)} / {n_total}\")\n",
    "            cnt = torch.zeros(len(CLASSES), dtype=torch.long)\n",
    "            for _, y in self.items: cnt[y] += 1\n",
    "            print(\"Class counts:\", dict(zip(CLASSES, cnt.tolist())))\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        p, y = self.items[i]\n",
    "        try:\n",
    "            img = Image.open(p).convert(\"RGB\")\n",
    "            if self.tf: \n",
    "                img = self.tf(img)\n",
    "            return img, y\n",
    "        except Exception as e:\n",
    "            # Uncomment to see which file failed:\n",
    "            # print(f\"[WARN] Failed to load {p}: {e}\")\n",
    "            return None\n",
    "\n",
    "# -----------------------\n",
    "# Try to reuse your existing balanced subsets if they exist\n",
    "# Otherwise, recreate from JSONLs (unaugmented – same as before)\n",
    "# -----------------------\n",
    "from torchvision import transforms\n",
    "\n",
    "tf_eval = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),     # match your img_size (256) if you changed it\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "need_build = False\n",
    "try:\n",
    "    ds_tr, ds_va  # already defined earlier?\n",
    "except NameError:\n",
    "    need_build = True\n",
    "\n",
    "if need_build:\n",
    "    train_jsonl = os.path.join(DATA_DIR, \"train.jsonl\")\n",
    "    val_jsonl   = os.path.join(DATA_DIR, \"val.jsonl\")\n",
    "    if not (os.path.isfile(train_jsonl) and os.path.isfile(val_jsonl)):\n",
    "        raise RuntimeError(\"train.jsonl / val.jsonl not found. Run your Step-5.A/B cells first.\")\n",
    "\n",
    "    ds_tr_full = LabeledImagesSafe(train_jsonl, DATA_DIR, transform=tf_eval, verbose=True)\n",
    "    ds_va_full = LabeledImagesSafe(val_jsonl,   DATA_DIR, transform=tf_eval, verbose=True)\n",
    "\n",
    "    # If you already created balanced subsets elsewhere, you can replace the next\n",
    "    # two lines with those subsets. Otherwise, use full sets here:\n",
    "    ds_tr = ds_tr_full\n",
    "    ds_va = ds_va_full\n",
    "\n",
    "# -----------------------\n",
    "# Build loaders (start with num_workers=0 to verify stability)\n",
    "# -----------------------\n",
    "BATCH_TR = 64\n",
    "BATCH_VA = 128\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    ds_tr, batch_size=BATCH_TR, shuffle=True,\n",
    "    num_workers=0, pin_memory=False, collate_fn=safe_collate\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    ds_va, batch_size=BATCH_VA, shuffle=False,\n",
    "    num_workers=0, pin_memory=False, collate_fn=safe_collate\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Quick sanity pass to confirm no crashes & not empty\n",
    "# -----------------------\n",
    "n_seen = 0\n",
    "for xb, yb in train_dl:\n",
    "    if xb.numel() == 0:    # all Nones in a batch -> skip\n",
    "        continue\n",
    "    n_seen += xb.size(0)\n",
    "    if n_seen >= 512:      # enough to prove it's stable\n",
    "        break\n",
    "print(\"Loaded OK, samples seen:\", n_seen)\n",
    "\n",
    "# (Optional) If stable, you can now bump workers:\n",
    "# train_dl = DataLoader(ds_tr, batch_size=BATCH_TR, shuffle=True,\n",
    "#                       num_workers=2, pin_memory=True, collate_fn=safe_collate)\n",
    "# val_dl   = DataLoader(ds_va, batch_size=BATCH_VA, shuffle=False,\n",
    "#                       num_workers=2, pin_memory=True, collate_fn=safe_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db6f4f4f-1d6f-4e9a-a7c8-be56e29900a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Epoch 1/10 | train_loss 1.1165 | train_acc 0.545 | val_acc 0.614 | time 79.1s\n",
      "Epoch 2/10 | train_loss 0.8047 | train_acc 0.688 | val_acc 0.634 | time 73.8s\n",
      "Epoch 3/10 | train_loss 0.6360 | train_acc 0.757 | val_acc 0.641 | time 73.1s\n",
      "Epoch 4/10 | train_loss 0.4989 | train_acc 0.817 | val_acc 0.520 | time 73.3s\n",
      "Epoch 5/10 | train_loss 0.4027 | train_acc 0.865 | val_acc 0.652 | time 73.1s\n",
      "Epoch 6/10 | train_loss 0.3022 | train_acc 0.891 | val_acc 0.574 | time 72.9s\n",
      "Epoch 7/10 | train_loss 0.2393 | train_acc 0.931 | val_acc 0.616 | time 72.8s\n",
      "Epoch 8/10 | train_loss 0.1820 | train_acc 0.956 | val_acc 0.638 | time 72.6s\n",
      "Epoch 9/10 | train_loss 0.1447 | train_acc 0.962 | val_acc 0.621 | time 72.6s\n",
      "Epoch 10/10 | train_loss 0.1481 | train_acc 0.953 | val_acc 0.623 | time 72.7s\n",
      "Best val acc: 0.6517857142857143\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# --- Model ---\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(CLASSES))\n",
    "model = model.to(device)\n",
    "\n",
    "# --- Loss & optimizer ---\n",
    "loss_fn = nn.CrossEntropyLoss(weight=ce_weights)   # from Step 5.B\n",
    "opt = optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=10)\n",
    "\n",
    "# --- Training loop ---\n",
    "EPOCHS = 10\n",
    "best_acc = 0.0\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    t0 = time.time()\n",
    "    # train\n",
    "    model.train()\n",
    "    total_loss, total, correct = 0.0, 0, 0\n",
    "    for xb, yb in train_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    train_loss = total_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # val\n",
    "    model.eval()\n",
    "    vtotal, vcorrect = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            pred = logits.argmax(1)\n",
    "            vcorrect += (pred == yb).sum().item()\n",
    "            vtotal += xb.size(0)\n",
    "\n",
    "    val_acc = vcorrect / vtotal\n",
    "    sched.step()\n",
    "\n",
    "    print(f\"Epoch {ep+1}/{EPOCHS} | train_loss {train_loss:.4f} | train_acc {train_acc:.3f} | val_acc {val_acc:.3f} | time {time.time()-t0:.1f}s\")\n",
    "\n",
    "    # save best\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"disaster-ai/models/cv/resnet18_multiclass.pt\")\n",
    "\n",
    "print(\"Best val acc:\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "360206ec-2a1e-40b0-8765-34c6fecfe3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint: disaster-ai/models/cv/resnet18_multiclass.pt\n"
     ]
    }
   ],
   "source": [
    "# --- robust checkpoint loader ---\n",
    "import os, glob, torch\n",
    "\n",
    "# prefer your intended name first, then try common fallbacks\n",
    "candidates = [\n",
    "    \"disaster-ai/models/cv/resnet18_multiclass.pt\",          # <- your file\n",
    "    *glob.glob(\"disaster-ai/models/cv/*multiclass*.pt\"),\n",
    "    *glob.glob(\"disaster-ai/models/cv/resnet18*.pt\"),\n",
    "    *glob.glob(\"disaster-ai/models/cv/*.pt\"),\n",
    "]\n",
    "\n",
    "ckpt_path = next((p for p in candidates if os.path.exists(p)), None)\n",
    "assert ckpt_path, f\"Couldn't find a checkpoint. Looked for:\\n\" + \"\\n\".join(candidates)\n",
    "\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "# some saves wrap weights as {'model': state_dict} or {'state_dict': state_dict}\n",
    "if isinstance(state, dict) and \"model\" in state and isinstance(state[\"model\"], dict):\n",
    "    state = state[\"model\"]\n",
    "elif isinstance(state, dict) and \"state_dict\" in state and isinstance(state[\"state_dict\"], dict):\n",
    "    state = state[\"state_dict\"]\n",
    "\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "print(f\"Loaded checkpoint: {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2da73174-ea20-4793-830b-5f60dbb1953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no-damage      0.817     0.751     0.782       261\n",
      "minor-damage      0.213     0.381     0.274        42\n",
      "major-damage      0.569     0.607     0.587        61\n",
      "   destroyed      0.632     0.512     0.566        84\n",
      "\n",
      "    accuracy                          0.652       448\n",
      "   macro avg      0.558     0.563     0.552       448\n",
      "weighted avg      0.692     0.652     0.668       448\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAHWCAYAAABOqjKFAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAiSxJREFUeJzs3XVYlFkbB+Df0N2SAgoCioJiI6K4BoiymLsWoGKLiogiFoiuumvnuusqdq+Nha2IDWIrGBiERSs15/uDj3cZAQWUCea595prmfPW8x5h5plTw2OMMRBCCCGECJGMqAMghBBCiPShBIQQQgghQkcJCCGEEEKEjhIQQgghhAgdJSCEEEIIETpKQAghhBAidJSAEEIIIUToKAEhhBBCiNBRAkIIIYQQoaMEhJDv8OTJE3Tp0gWamprg8Xg4cODADz3/8+fPwePxsHHjxh96Xknm4uICFxcXUYchcufOnQOPx8O5c+e+uW9Vf482btwIHo+H58+fVylGQr6GEhAi8RISEjBy5EhYWFhASUkJGhoacHJywvLly/Hp06dqvbaPjw/u3LmD3377DVu2bEHz5s2r9XrCNHjwYPB4PGhoaJRZj0+ePAGPxwOPx8OiRYsqff43b94gNDQUsbGxPyBa8VL8hs/j8TB37twy9xk4cCB4PB7U1NR+2HW3b9+OZcuW/bDzEVKd5EQdACHfIyIiAn379oWioiK8vb3RqFEj5OXl4dKlS5g8eTLu3buHv//+u1qu/enTJ0RHR2P69Onw8/OrlmuYm5vj06dPkJeXr5bzf4ucnBxycnJw+PBh/PLLLwLbtm3bBiUlJXz+/LlK537z5g1mz56NOnXqoEmTJhU+7uTJk1W6nigoKSlhx44dmDFjhkB5dnY2Dh48CCUlpR96ve3bt+Pu3bvw9/cXKBf17xEhZaEWECKxnj17hn79+sHc3Bz379/H8uXLMXz4cIwdOxY7duzA/fv30bBhw2q7/tu3bwEAWlpa1XYNHo8HJSUlyMrKVts1vkZRUREdO3bEjh07Sm3bvn07unXrJrRYcnJyAAAKCgpQUFAQ2nW/h7u7O+7fv4/bt28LlB88eBB5eXno3LmzUOIQ9e8RIWWhBIRIrD/++ANZWVlYv349jIyMSm2vV68eJkyYwD0vKCjAnDlzYGlpCUVFRdSpUwfTpk1Dbm6uwHF16tRB9+7dcenSJbRs2RJKSkqwsLDA5s2buX1CQ0Nhbm4OAJg8eTJ4PB7q1KkDoKjrovjnkkJDQ8Hj8QTKIiMj0bZtW2hpaUFNTQ02NjaYNm0at728vvszZ87A2dkZqqqq0NLSgqenJx48eFDm9eLj4zF48GBoaWlBU1MTQ4YM4d7MK2LAgAE4duwY0tLSuLLr16/jyZMnGDBgQKn9P3z4gMDAQNjZ2UFNTQ0aGhro2rWrwJvwuXPn0KJFCwDAkCFDuO6K4vt0cXFBo0aNcPPmTbRr1w4qKipcvXw5BsTHxwdKSkql7t/V1RXa2tp48+ZNhe/1R3N0dETdunWxfft2gfJt27bBzc0NOjo6pY7h8XgIDQ0tVV6nTh0MHjy43Gu5uLggIiICL1684Oqz+PewvN+jhw8f4pdffkGtWrWgrKwMGxsbTJ8+/av3dPDgQXTr1g3GxsZQVFSEpaUl5syZg8LCQoH9njx5gt69e8PQ0BBKSkqoXbs2+vXrh/T0dG6fb/3+k5qNumCIxDp8+DAsLCzQpk2bCu0/bNgwbNq0CX369MGkSZNw9epVzJ8/Hw8ePMD+/fsF9o2Pj0efPn3g6+sLHx8fbNiwAYMHD0azZs3QsGFD9OrVC1paWpg4cSL69+8Pd3f3Svfl37t3D927d4e9vT3CwsKgqKiI+Ph4REVFffW4U6dOoWvXrrCwsEBoaCg+ffqElStXwsnJCbdu3SqV/Pzyyy+oW7cu5s+fj1u3buGff/6Bvr4+fv/99wrF2atXL4waNQr79u3D0KFDARS1ftSvXx9NmzYttf/Tp09x4MAB9O3bF3Xr1kVKSgr++usvtG/fHvfv34exsTEaNGiAsLAwzJo1CyNGjICzszMACPxbvn//Hl27dkW/fv0waNAgGBgYlBnf8uXLcebMGfj4+CA6OhqysrL466+/cPLkSWzZsgXGxsYVus/q0r9/f2zduhULFiwAj8fDu3fvuNiOHz/+w64zffp0pKen49WrV1i6dCkAfPV3Mi4uDs7OzpCXl8eIESNQp04dJCQk4PDhw/jtt9/KPW7jxo1QU1NDQEAA1NTUcObMGcyaNQsZGRlYuHAhACAvLw+urq7Izc3FuHHjYGhoiNevX+PIkSNIS0uDpqZmlX//SQ3CCJFA6enpDADz9PSs0P6xsbEMABs2bJhAeWBgIAPAzpw5w5WZm5szAOzChQtcWWpqKlNUVGSTJk3iyp49e8YAsIULFwqc08fHh5mbm5eKISQkhJX8k1u6dCkDwN6+fVtu3MXXCA8P58qaNGnC9PX12fv377my27dvMxkZGebt7V3qekOHDhU4Z8+ePZmurm651yx5H6qqqowxxvr06cM6duzIGGOssLCQGRoastmzZ5dZB58/f2aFhYWl7kNRUZGFhYVxZdevXy91b8Xat2/PALC1a9eWua19+/YCZSdOnGAA2Ny5c9nTp0+Zmpoa69GjxzfvsbqUrJe7d+8yAOzixYuMMcZWr17N1NTUWHZ2tkAdFwPAQkJCSp3T3Nyc+fj4cM/Pnj3LALCzZ89yZd26dSvzd6+s36N27doxdXV19uLFC4F9+Xw+93N4eDgDwJ49e8aV5eTklDr/yJEjmYqKCvv8+TNjjLGYmBgGgO3Zs6fUvsUq8vtPajbqgiESKSMjAwCgrq5eof2PHj0KAAgICBAonzRpEoCiwawl2dracp/KAaBWrVqwsbHB06dPqxzzl4rHjhw8eBB8Pr9CxyQlJSE2NhaDBw8WaL63t7dH586dufssadSoUQLPnZ2d8f79e64OK2LAgAE4d+4ckpOTcebMGSQnJ5fZ/QIUjRuRkSl6aSksLMT79++55vVbt25V+JqKiooYMmRIhfbt0qULRo4cibCwMPTq1QtKSkr466+/Knyt6tSwYUPY29tz42i2b98OT09PqKioiCymt2/f4sKFCxg6dCjMzMwEtn3ZTfglZWVl7ufMzEy8e/cOzs7OyMnJwcOHDwEAmpqaAIATJ06U291Xld9/UrNQAkIkkoaGBoCiF8CKePHiBWRkZFCvXj2BckNDQ2hpaeHFixcC5V++KAOAtrY2Pn78WMWIS/v111/h5OSEYcOGwcDAAP369cPu3bu/+mJcHKeNjU2pbQ0aNMC7d++QnZ0tUP7lvWhrawNApe7F3d0d6urq2LVrF7Zt24YWLVqUqstifD4fS5cuhZWVFRQVFaGnp4datWohLi5OoP//W0xMTCo12HTRokXQ0dFBbGwsVqxYAX19/W8e8/btWyQnJ1fp8eWYh68ZMGAA9uzZg/j4eFy+fLnc5E1YihPpRo0aVfrYe/fuoWfPntDU1ISGhgZq1aqFQYMGAQD371u3bl0EBATgn3/+gZ6eHlxdXbF69WqBf/+q/P6TmoUSECKRNDQ0YGxsjLt371bquG99uitW3mwBxliVr/HlG5aysjIuXLiAU6dOwcvLC3Fxcfj111/RuXPnSr25fcv33EsxRUVF9OrVC5s2bcL+/fu/+gY6b948BAQEoF27dti6dStOnDiByMhINGzYsFJvLiU/aVdETEwMUlNTAQB37typ0DEtWrSAkZFRlR4vX76scGz9+/fHu3fvMHz4cOjq6qJLly6Vujeg9O+PKKSlpaF9+/a4ffs2wsLCcPjwYURGRnLjiUr++y5evBhxcXGYNm0aPn36hPHjx6Nhw4Z49eoVAOH9/hPxRYNQicTq3r07/v77b0RHR8PR0fGr+5qbm4PP5+PJkydo0KABV56SkoK0tDRuRsuPoK2tLTBjpNiXrSwAICMjg44dO6Jjx45YsmQJ5s2bh+nTp+Ps2bPo1KlTmfcBAI8ePSq17eHDh9DT04Oqqur330QZBgwYgA0bNkBGRgb9+vUrd7+9e/eiQ4cOWL9+vUB5Wloa9PT0uOcVTQYrIjs7G0OGDIGtrS3atGmDP/74Az179uRm2pRn27ZtVV6sztDQsML7mpmZwcnJCefOncPo0aMhJ1f+S29Zvz95eXlISkr65nUqWqcWFhYAUOkE/ty5c3j//j327duHdu3aceXPnj0rc387OzvY2dlhxowZuHz5MpycnLB27VpucbbK/v6TmoUSECKxpkyZgm3btmHYsGE4c+ZMqVkSCQkJOHLkCCZMmAB3d3dMmzYNy5YtExgbsGTJEgD4oetZWFpaIj09HXFxcbC3twdQNHbjy5k2Hz58KDUNs3hBri+nBhczMjJCkyZNsGnTJgQHB3P96Hfv3sXJkye5pvDq0KFDB8yZMwe6urpfffOVlZUt1bqyZ88evH79WqDbpjhRKitZq6ygoCAkJibiypUrsLGxwenTp+Hj44OYmBgoKiqWe5yTk9N3X7ui5s6di7Nnz+LXX3/96n6Wlpa4cOGCQNnff/9doVYBVVXVCnVz1apVC+3atcOGDRsQEBAg0E3HGCs3kSluTSv575uXl4c1a9YI7JeRkQEVFRWBRMvOzg4yMjLc73ZVfv9JzUIJCJFYlpaW2L59O3799Vc0aNBAYCXUy5cvY8+ePdy6CY0bN4aPjw/+/vtvrhn52rVr2LRpE3r06IEOHTr8sLj69euHoKAg9OzZE+PHj0dOTg7+/PNPWFtbCwzCDAsLw4ULF9CtWzeYm5sjNTUVa9asQe3atdG2bdtyz79w4UJ07doVjo6O8PX15abhampqlrl+xI8iIyNTakXPsnTv3h1hYWEYMmQI2rRpgzt37mDbtm3cp+5ilpaW0NLSwtq1a6Gurg5VVVW0atUKdevWrVRcZ86cwZo1axASEsJNCw4PD4eLiwtmzpyJP/74o1Lnqy7t27dH+/btv7nfsGHDMGrUKPTu3RudO3fG7du3ceLECYHWo/I0a9YMu3btQkBAAFq0aAE1NTV4eHiUue+KFSvQtm1bNG3aFCNGjEDdunXx/PlzRERElLs8fps2baCtrQ0fHx+MHz8ePB4PW7ZsKZVwnjlzBn5+fujbty+sra1RUFCALVu2QFZWFr179wZQ9d9/UoOIcgoOIT/C48eP2fDhw1mdOnWYgoICU1dXZ05OTmzlypXctEDGGMvPz2ezZ89mdevWZfLy8szU1JQFBwcL7MNY0XTHbt26lbrOl9M/y5uGyxhjJ0+eZI0aNWIKCgrMxsaGbd26tdQ03NOnTzNPT09mbGzMFBQUmLGxMevfvz97/PhxqWt8OVX11KlTzMnJiSkrKzMNDQ3m4eHB7t+/L7BP8fW+nOZY1tTKspQ1RfRL5U3DnTRpEjMyMmLKysrMycmJRUdHlzl99uDBg8zW1pbJyckJ3Gf79u1Zw4YNy7xmyfNkZGQwc3Nz1rRpU5afny+w38SJE5mMjAyLjo7+6j1Uh6/9bpRUVh0XFhayoKAgpqenx1RUVJirqyuLj4+v0DTcrKwsNmDAAKalpcUAcFNyy/s9unv3LuvZsyfT0tJiSkpKzMbGhs2cOZPbXtbvSlRUFGvdujVTVlZmxsbGbMqUKdw06OJYnj59yoYOHcosLS2ZkpIS09HRYR06dGCnTp3izlOR339Ss/EYq8RINEIIIYSQH4BmwRBCCCFE6CgBIYQQQojQUQJCCCGEEKGjBIQQQgghQkcJCCGEEEKEjhIQQgghhAgdLURGKoXP5+PNmzdQV1f/oUtpE0KIuGGMITMzE8bGxtw3PFeXz58/Iy8vr8rHKygoQElJ6QdGVP0oASGV8ubNG5iamoo6DEIIEZqXL1+idu3a1Xb+z58/Q1ldFyjIqfI5DA0N8ezZM4lKQigBIZWirq4OAFCw9QFPtuJflU6KnN4RIuoQJJaFgZqoQ5Bo6Tn5og5B4mRlZqJFIwvuda+65OXlAQU5ULT1AaryulqYh+T7m5CXl0cJCKm5irtdeLIKlIBUgZq6hqhDkFgaGpSAfA++HCUgVSW07mY5pSq9rjKeZA7npASEEEIIEQc8AFVJdiR0OB4lIIQQQog44MkUPapynASiBIQQQggRBzxeFVtAJLMJRDLTJkIIIYRINGoBIYQQQsQBdcEQQgghROikrAuGEhBCCCFELFSxBURCR1NQAkIIIYSIA2oBIYQQQojQSdkYEMmMmhBCCCESjVpACCGEEHFAXTCEEEIIETop64KhBIQQQggRB9QCQgghhBChk7IWEMmMmhBCCCESjVpACCGEEHHA41WxBYS6YAghhBBSVTK8okdVjpNAlIAQQggh4kDKxoBQAkIIIYSIAymbBSOZaRMhhBBCJBq1gBBCCCHigLpgCCGEECJ0UtYFQwkIIYQQIg6oBYQQQgghQidlLSCSmTYRQgghRKJRCwghhBAiDqgLhhBCCCFCR10whBBCCBE+mf9aQSrzqORb+YULF+Dh4QFjY2PweDwcOHBAYDuPxyvzsXDhQm6fOnXqlNq+YMGCSsVBLSCEEEKIOBBSC0h2djYaN26MoUOHolevXqW2JyUlCTw/duwYfH190bt3b4HysLAwDB8+nHuurq5eqTgoASGEEEKkSNeuXdG1a9dytxsaGgo8P3jwIDp06AALCwuBcnV19VL7VgZ1wRBCCCHigMerWhdMNY4BSUlJQUREBHx9fUttW7BgAXR1deHg4ICFCxeioKCgUuemBOQ7bNy4EVpaWqIOo8bjZ71B3tMIfL4bjs+xq1GY9lRgO8vPQd6L00Xbb/+FvITD4OemlT5PdjLy4g/gc9xf+Bz3N3Kf7APjV+4PpibZsGYJmphr4I/ZQVxZ7ufPmDcjAO0bm8OxgREmjRyE929TRRil+PptTijUFGUEHg52DUQdllhateQPdPupDWxMddHYqjZ8B/ZBwpNHAvt8/vwZ0wPHo5GFEaxr62C49694m5oioohFpErJx38zZzIyMgQeubm53x3Spk2boK6uXqqrZvz48di5cyfOnj2LkSNHYt68eZgyZUqlzk0JCBF7jJ8PnrIu5Gu3L72NMeQ9OwqWlw4FC3co2PwCnoIa8uIPghXmc/vxs5ORl3AYMuqmULDqAwXrvpDTswMgmaPHv9fd2zexd1s4rBs0EihfNCcYF04fx8I1m7F+91G8TUlCwMiBIopS/DWwbYiEF2+4R+TZi6IOSSxFX74An2GjcOjkRezYdxT5+fkY0Ks7crKzuX1mTwtE5PGj+Gvjduw9cgopyUkY7vWrCKMWgeIxIFV5ADA1NYWmpib3mD9//neHtGHDBgwcOBBKSkoC5QEBAXBxcYG9vT1GjRqFxYsXY+XKlZVKemgMCBF7shrmkNUwBwDkf7GN5aaD5aRAwaYfZJR1AQC82i4ovBeOwrQnkNO1LTru9SXI1rKHnEGz/w5W0hZG+GInJzsL0yYMw6zfV2Ddyv9GtWdmpGP/rs2Yv3w9WjoVJXuzF/2Jnh2bI+7WNdg3bSmqkMWWnJwcDL6jD1xabNt7ROD50jX/oLFVbcTF3kJrJ2dkpKdj59aNWLluM5zadQAALFn1N1xaNcbN61fRrEUrUYQtfN+5DsjLly+hoaHBFSsqKn5XOBcvXsSjR4+wa9eub+7bqlUrFBQU4Pnz57CxsanQ+WtkC4iLiwvGjx+PKVOmQEdHB4aGhggNDeW2JyYmwtPTE2pqatDQ0MAvv/yClJRvN/Vt3LgRZmZmUFFRQc+ePfH+/XuB7QkJCfD09ISBgQHU1NTQokULnDp1SmCfOnXqYO7cufD29oaamhrMzc1x6NAhvH37lovJ3t4eN27c4I55//49+vfvDxMTE6ioqMDOzg47duwQOG9mZiYGDhwIVVVVGBkZYenSpXBxcYG/vz+3T25uLgIDA2FiYgJVVVW0atUK586dq3jFiiNWWPR/mf9yaR6PB/Bkwc8qGsnN8nPAclLAk1NG7uN/8fnuBuQ+2Q9+1htRRCxy82ZOgvNPrmjdtoNA+YM7sSjIz0erti5cWd161jAyMcXtW9eEHKVkSIh/gnp1TNDIxhJDfQbhZWKiqEOSCBkZ6QAALW0dAMCd27eQn58PZ5efuH3qWdeHSW0z3Lp+RSQxisR3toBoaGgIPL43AVm/fj2aNWuGxo0bf3Pf2NhYyMjIQF9fv8Lnr5EJCFDUb6WqqoqrV6/ijz/+QFhYGCIjI8Hn8+Hp6YkPHz7g/PnziIyMxNOnT/Hrr19v6rt69Sp8fX3h5+eH2NhYdOjQAXPnzhXYJysrC+7u7jh9+jRiYmLg5uYGDw8PJH7xorR06VI4OTkhJiYG3bp1g5eXF7y9vTFo0CDcunULlpaW8Pb2BmMMQFHfaLNmzRAREYG7d+9ixIgR8PLywrVr/70pBAQEICoqCocOHUJkZCQuXryIW7duCVzXz88P0dHR2LlzJ+Li4tC3b1+4ubnhyZMn31PVIsVT0gLk1VCQFA1W8BmMX4iClFtAfhZQUNS8y/IyAAAFydcgq2sLBQsPyKjUQl7CwTLHitRkxw/txcO7tzF+Smipbe/epkBeQQEamloC5Tp6tWgcSBlatGiFtf+E48DhY1i2cg1ePH+GLh3bITMzU9ShiTU+n4/Q4EC0aNUG9W0bAgBSU1KgoKAAzS9+9/T09ZFagQ+HpHKysrIQGxuL2NhYAMCzZ88QGxsr8F6VkZGBPXv2YNiwYaWOj46OxrJly3D79m08ffoU27Ztw8SJEzFo0CBoa1e8ZbnGdsHY29sjJCQEAGBlZYVVq1bh9OnTAIA7d+7g2bNnMDU1BQBs3rwZDRs2xPXr19GiRYsyz7d8+XK4ublxg2ysra1x+fJlHD9+nNuncePGApninDlzsH//fhw6dAh+fn5cubu7O0aOHAkAmDVrFv7880+0aNECffv2BQAEBQXB0dERKSkpMDQ0hImJCQIDA7njx40bhxMnTmD37t1o2bIlMjMzsWnTJmzfvh0dO3YEAISHh8PY2Jg7JjExEeHh4UhMTOTKAwMDcfz4cYSHh2PevHll3ndubq5An15GRkb5lS4CPJ4sFOp2RX7iGeTeXQ+ABxl1U8iom5XYqyiRk9VtCDndokGCMiq1wM98hcL3DyBj7Cj8wEUg+c0r/DE7CGu3HoTiF/25pPK6uP03jbGRnT2at2wFW6s62Ld3N3yGlJ4xQIpMDxyPRw/uY9+xM6IORfwIaSn2GzduoEOH/1pAAwICAAA+Pj7YuHEjAGDnzp1gjKF///6ljldUVMTOnTsRGhqK3Nxc1K1bFxMnTuTOU1E1OgEpycjICKmpqXjw4AFMTU255AMAbG1toaWlhQcPHqBFixZo2LAhXrx4AQBwdnbGsWPH8ODBA/Ts2VPgnI6OjgIJSFZWFkJDQxEREYGkpCQUFBTg06dPpVpASsZmYGAAALCzsytVlpqaCkNDQxQWFmLevHnYvXs3Xr9+jby8POTm5kJFRQUA8PTpU+Tn56Nly//66DU1NQX64e7cuYPCwkJYW1sLxJKbmwtdXd1y63H+/PmYPXt2udvFgYyKPhTr9wMrzAUY//9dLXsgo/L/pkA51aL9lHQEjuMpaYPlS8+n1ft3YvHh3Vv07+bMlRUWFuLW1Sjs2vQ31mzej/y8PGSkpwm0gnx49xa6tSrerCqttLS0UM/KGk8T4kUditiaPnkCTp04hn+PnoKxSW2uXN/AAHl5eUhPTxNoBXmXmgr9/78eSgUhLUTm4uLCtbCXZ8SIERgxYkSZ25o2bYorV76/a6zGJiDy8vICz3k8Hvh8foWOPXq0aJQ2ACgrK1f4moGBgYiMjMSiRYtQr149KCsro0+fPsjLyys3Nt7/f3HKKiuOd+HChVi+fDmWLVsGOzs7qKqqwt/fv9R5vyYrKwuysrK4efMmZGVlBbapqamVe1xwcLBAVpuRkSGQvIkTnmxRfyc/Nw0s5y1kDIsGrvEU1AF5VfBz01Dyzllu2hctJTVbK6f22HtS8EVjVuBo1LW0xpDRE2FgZAI5eXlcizqPTu6eAIDnCU+Q9PolGtMA1G/KysrCs6cJ6DdgkKhDETuMMcyY4o/jEYew5/BJmJnXFdhu17gp5OXlcen8WXT7ueiDXsKTR3j9KhFNW7QWRcgiUbykeRUO/PHBCEGNTUDK06BBA7x8+RIvX77k3kjv37+PtLQ02NoWzZgwNzcv87irV68KlH2ZAUZFRWHw4MFcS0lWVhaeP3/+3TFHRUXB09MTgwYVvbDx+Xw8fvyYi9fCwgLy8vK4fv06zMyK3lDT09Px+PFjtGvXDgDg4OCAwsJCpKamwtnZuewLlUFRUfG7BzJ9L1aYB5ab/t/zvAzwc96CJ6cEnoI6CtPiAVll8BTUwD6/R/6rS5DRrAtZjaK64PF4kKvlgILka5BR1gVPWQ+FHx6Bff4I2TpuorotoVNVU0c9G1uBMmUVVWhq63DlPX/1xuK506CppQ1VdXUsmDUZ9k1b0gyYMkwLCkTXbh4wMzNHUtIb/BYWChlZWfT9tXSTtbSbHjgeB/buwvrte6Gmpo7UlGQAgLqGJpSVlaGhqYl+gwYjbPoUaGlrQ11dAzOnTESzFq2lZwYMKAGp8Tp16gQ7OzsMHDgQy5YtQ0FBAcaMGYP27dujefPm5R43fvx4ODk5YdGiRfD09MSJEycEul+AorEm+/btg4eHB3g8HmbOnFnhVpevsbKywt69e3H58mVoa2tjyZIlSElJ4RIQdXV1+Pj4YPLkydDR0YG+vj5CQkIgIyPD/TJbW1tj4MCB8Pb2xuLFi+Hg4IC3b9/i9OnTsLe3R7du3b47zurCz3mL/IQD3POCN1EAABnt+lAw7wiWn42C11FAQQ4gpwJZnfqQMxD8t5TTbwywAuS/jgIKP4OnpAcFy58ho6gpzFsRe4Ez54PH42HSqEHIy8tDm3YdMW3uElGHJZZev36NId4D8OH9e+jVqgXHNm1x9kI0atWqJerQxM7mDX8DAPp27yxQvmT1OvwywBsAEDJvEWRkZDDCux/y8nLR/qfOmLdohdBjJcIjdQkIj8fDwYMHMW7cOLRr1w4yMjJwc3PDypUrv3pc69atsW7dOoSEhGDWrFno1KkTZsyYgTlz5nD7LFmyBEOHDkWbNm2gp6eHoKCgHzJoc8aMGXj69ClcXV2hoqKCESNGoEePHkhP/69VYMmSJRg1ahS6d+8ODQ0NTJkyBS9fvhRYPCY8PBxz587FpEmT8Pr1a+jp6aF169bo3r37d8dYnWTVTSDbZGy52+VqNYZcrW9PE5MzaCa4DgjB+l1HBZ4rKilh2twllHRUwKatO769EwEAvPr47cWplJSU8NuiFfhNmpMOHqq2NqJkNoCAx741EoVIpOzsbJiYmGDx4sVlruFfVRkZGdDU1ISi3XDwZBV+2HmlxZWD378yobSqZ1j+WCXybWk5Xy7jR74lMyMDDcxrIT09XWCBrx+t+HVVpcca8OQrPu6wGMv/hJwDY6o9zh9N6lpAaqqYmBg8fPgQLVu2RHp6OsLCwgAAnp6eIo6MEEJIRdAYECKxFi1ahEePHkFBQQHNmjXDxYsXoaenJ+qwCCGEVAAlIEQiOTg44ObNm6IOgxBCCKkQSkAIIYQQMUAtIIQQQggRPimbBUMJCCGEECIGqAWEEEIIIUJX9FUwVUlAfnwswlCFr90jhBBCCPk+1AJCCCGEiAEeqtgFI6FNIJSAEEIIIWKAxoAQQgghRPhoFgwhhBBChK6KLSCMWkAIIYQQUlVV7YKp2rgR0aNZMIQQQggROmoBIYQQQsSAtLWAUAJCCCGEiAMahEoIIYQQYaMWEEIIIYQInbQlIDQIlRBCCCFCRy0ghBBCiBiQthYQSkAIIYQQMUAJCCGEEEKEj2bBEEIIIUTYpK0FhAahEkIIIUToqAWEEEIIEQPUAkIIIYQQoStOQKryqIwLFy7Aw8MDxsbG4PF4OHDggMD2wYMHlzq/m5ubwD4fPnzAwIEDoaGhAS0tLfj6+iIrK6tScVACQgghhIgD3nc8KiE7OxuNGzfG6tWry93Hzc0NSUlJ3GPHjh0C2wcOHIh79+4hMjISR44cwYULFzBixIhKxUFdMIQQQogYEFYXTNeuXdG1a9ev7qOoqAhDQ8Mytz148ADHjx/H9evX0bx5cwDAypUr4e7ujkWLFsHY2LhCcVALCCGEEFIDZGRkCDxyc3OrfK5z585BX18fNjY2GD16NN6/f89ti46OhpaWFpd8AECnTp0gIyODq1evVvgalIAQQgghYuB7x4CYmppCU1OTe8yfP79Kcbi5uWHz5s04ffo0fv/9d5w/fx5du3ZFYWEhACA5ORn6+voCx8jJyUFHRwfJyckVvg51wRBCCCFigIcqdsH8fxDIy5cvoaGhwZUrKipWKY5+/fpxP9vZ2cHe3h6WlpY4d+4cOnbsWKVzloVaQAghhBAx8L0tIBoaGgKPqiYgX7KwsICenh7i4+MBAIaGhkhNTRXYp6CgAB8+fCh33EhZKAEhhBBCxIGQZsFU1qtXr/D+/XsYGRkBABwdHZGWloabN29y+5w5cwZ8Ph+tWrWq8HmpC4ZUyYPjC6BeoqmPVEwhn4k6BImVX8gXdQgSTUdVXtQhSBy5wppZZ1lZWVxrBgA8e/YMsbGx0NHRgY6ODmbPno3evXvD0NAQCQkJmDJlCurVqwdXV1cAQIMGDeDm5obhw4dj7dq1yM/Ph5+fH/r161fhGTAAtYAQQgghYkFYC5HduHEDDg4OcHBwAAAEBATAwcEBs2bNgqysLOLi4vDzzz/D2toavr6+aNasGS5evCjQpbNt2zbUr18fHTt2hLu7O9q2bYu///67UnFQCwghhBAiBoS1DoiLiwsYK7819sSJE988h46ODrZv316p636JEhBCCCFEDPB4RY+qHCeJKAEhhBBCxEBRAlKVFpBqCEYIKAEhhBBCxEEVW0CqexZMdaFBqIQQQggROmoBIYQQQsSAsAahigtKQAghhBAxQINQCSGEECJ0MjI8yMhUPptgVThGHFACQgghhIgBaWsBoUGohBBCCBE6agEhhBBCxAANQiWEEEKI0ElbFwwlIIQQQogYoBYQQgghhAidtCUgNAiVEEIIIUJHLSCEEEKIGKAxIIQQQggROh6q2AUjod9GRwkIIYQQIgaoBYQQQgghQkeDUAkhhBBCqhm1gBBCCCFigLpgCCGEECJ00tYFQwkIIYQQIgaoBYQQQgghQidtLSA0CJUQQgghQkctIIQQQog4qGIXjISuQ0YJCCGEECIOpK0LhhIQQgghRAzQIFRCCCGECB21gBBCCCFE6KStBYRmwRBCCCFE6CgBIYQQQsRAcRdMVR6VceHCBXh4eMDY2Bg8Hg8HDhzgtuXn5yMoKAh2dnZQVVWFsbExvL298ebNG4Fz1KlTp1QMCxYsqFQclIAQiXP50kUM7NsDjazMUEtdHkcPHyx338AJY1BLXR5rVy8XYoTiKzrqIrx+7YHGNuYw1FTAsSOl6+7xowfw7tcTVqZ6qGukBVcXR7x6mSiCaMVfZmYmgicHwM7GAkY6aujSoS1u3bgu6rAkwt9//YmWTRvDQFcTBrqacHFugxPHj4k6LJESVgKSnZ2Nxo0bY/Xq1aW25eTk4NatW5g5cyZu3bqFffv24dGjR/j5559L7RsWFoakpCTuMW7cuErFIVFjQM6dO4cOHTrg48eP0NLSEnU42LhxI/z9/ZGWlibqUKRKTk42GtrZY4DXYAwe2Lfc/SIOHcCN61dhaGQsxOjEW05ONho2skf/QYMxdNAvpbY/f5oAT9cO6O81GJODZ0FdXQOPHt6HopKSCKIVfxPGjMCD+/ewdv1GGBkZY/eObejR3RVXbt6BsYmJqMMTayYmtRH223zUq2cFxhi2btmEX3r3QPS1W7Bt2FDU4YmEsMaAdO3aFV27di1zm6amJiIjIwXKVq1ahZYtWyIxMRFmZmZcubq6OgwNDSsdbzGJSkDatGmDpKQkaGpqijoUIkKdurihUxe3r+6T9OY1gif7Y/eBCAzo4ymkyMRfx85u6Ni5/LqbP2cWOnZxw6w5/zWl1rGwFEZoEufTp084dGAftu3eB6e27QAAU2eE4PjRCGxYtxYzQueIOELx1q27h8Dz2XN+wz9/r8W1a1ekOAH5vlkwGRkZAuWKiopQVFT87rjS09PB4/FKffBfsGAB5syZAzMzMwwYMAATJ06EnFzF0wqJ6oJRUFCAoaFhtU85ys/Pr9bzk+rF5/MxZvhgjJ0QgPoNpPOFrCr4fD5OnTwGi3pW6NezGxpamqDrT05ldtMQoKCgAIWFhVD6onVISVkJV6KjRBSVZCosLMSeXTuRnZ2NVq0cRR2OxDI1NYWmpib3mD9//nef8/PnzwgKCkL//v2hoaHBlY8fPx47d+7E2bNnMXLkSMybNw9Tpkyp1LlFmoC4uLhg3Lhx8Pf3h7a2NgwMDLBu3TpkZ2djyJAhUFdXR7169XDsWFG/4Llz58Dj8bguj40bN0JLSwsnTpxAgwYNoKamBjc3NyQlJXHX4PP5CAsLQ+3ataGoqIgmTZrg+PHj3Pbnz5+Dx+Nh165daN++PZSUlLBt27Yy4924cSPMzMygoqKCnj174v379wLbExIS4OnpCQMDA6ipqaFFixY4deqUwD516tTB3Llz4e3tDTU1NZibm+PQoUN4+/YtPD09oaamBnt7e9y4cYM75v379+jfvz9MTEygoqICOzs77NixQ+C8mZmZGDhwIFRVVWFkZISlS5fCxcUF/v7+3D65ubkIDAyEiYkJVFVV0apVK5w7d67C/16SYsWShZCTk8OI0ZXrj5R2796mIjsrCyuXLkSHTl2wa38E3Lt7YuigX3D50gVRhyd21NXV0aJVayxc8BuS3rxBYWEhdu3YhutXryAlOVnU4UmEu3fuoJa2OrTUlDDebzR27tmHBra2og5LZIq7YKryAICXL18iPT2dewQHB39XPPn5+fjll1/AGMOff/4psC0gIAAuLi6wt7fHqFGjsHjxYqxcuRK5ubkVPr/IW0A2bdoEPT09XLt2DePGjcPo0aPRt29ftGnTBrdu3UKXLl3g5eWFnJycMo/PycnBokWLsGXLFly4cAGJiYkIDAzkti9fvhyLFy/GokWLEBcXB1dXV/z888948uSJwHmmTp2KCRMm4MGDB3B1dS11natXr8LX1xd+fn6IjY1Fhw4dMHfuXIF9srKy4O7ujtOnTyMmJgZubm7w8PBAYqLgAL6lS5fCyckJMTEx6NatG7y8vODt7Y1Bgwbh1q1bsLS0hLe3NxhjAIoy0GbNmiEiIgJ3797FiBEj4OXlhWvXrnHnDAgIQFRUFA4dOoTIyEhcvHgRt27dEriun58foqOjsXPnTsTFxaFv375wc3MrVRcl5ebmIiMjQ+Ahzm7H3MTff67EyrXrJXZxHlHh8/kAADd3D4wcOwGN7JtgXMAUdHZzx+YNf4s4OvH01/pNYIzBtp4ZDLRU8Pealej9Sz/IyIj8pVUiWNvY4Mr1GJyPuoLhI0ZhhO9gPLh/X9Rhicz3DkLV0NAQeHxP90tx8vHixQtERkYKtH6UpVWrVigoKMDz588rfA2R/5U0btwYM2bMgJWVFYKDg6GkpAQ9PT0MHz4cVlZWmDVrFt6/f4+4uLgyj8/Pz8fatWvRvHlzNG3aFH5+fjh9+jS3fdGiRQgKCkK/fv1gY2OD33//HU2aNMGyZcsEzuPv749evXqhbt26MDIyKnWd5cuXw83NDVOmTIG1tTXGjx9fKlFp3LgxRo4ciUaNGsHKygpz5syBpaUlDh06JLCfu7s7Ro4cyd1fRkYGWrRogb59+8La2hpBQUF48OABUlJSAAAmJiYIDAxEkyZNYGFhgXHjxsHNzQ27d+8GUNT6sWnTJixatAgdO3ZEo0aNEB4ejsLCQu6aiYmJCA8Px549e+Ds7AxLS0sEBgaibdu2CA8PL/ffZ/78+QJNeqampuXuKw6iL1/Cu7epaNLAAoZaSjDUUsLLxBcImTYFTRvWE3V4Yk1HVw9ycnKwrt9AoNzKuj5ev3opoqjEW10LS0ScPItXb9Nx9/FznL54BQX5+TCvU1fUoUkEBQUFWNarh6ZNmyHst/mws2+M1aukd8YaD1VsAfnBcRQnH0+ePMGpU6egq6v7zWNiY2MhIyMDfX39Cl9H5INQ7e3tuZ9lZWWhq6sLOzs7rszAwAAAkJqaWmYGpqKiAkvL/wbJGRkZITU1FUDRgJw3b97AyclJ4BgnJyfcvn1boKx58+bczw0bNsSLFy8AAM7Ozjh27BgePHiAnj17Chzj6Ogo0J2TlZWF0NBQREREICkpCQUFBfj06VOpFpCS91x8f+Xds6GhIQoLCzFv3jzs3r0br1+/Rl5eHnJzc6GiogIAePr0KfLz89GyZUvuHJqamrCxseGe37lzB4WFhbC2thaIJTc396u/XMHBwQgICOCeZ2RkiHUS8ku/QWjfoaNgWY9u6NtvIAYM8hFRVJJBQUEBTZo2R8KTxwLlTxOeoLapWTlHEQBQVVWFqqoq0j5+xOlTJzF7buXWQyBF+Hw+8nLzRB2GyMjweJCpQsttZY/JyspCfHw89/zZs2eIjY2Fjo4OjIyM0KdPH9y6dQtHjhxBYWEhkv/fpaijowMFBQVER0fj6tWr6NChA9TV1REdHY2JEydi0KBB0NbWrnAcIk9A5OXlBZ7zeDyBsuKmpeLm4YocX9x1URmqqqrcz0ePHuUGoiorK1f4HIGBgYiMjMSiRYtQr149KCsro0+fPsjLE/yDKuv+vnbPCxcuxPLly7Fs2TJucRh/f/9S5/2arKwsyMrK4ubNm5CVlRXYpqamVu5xP2oU9Y+UlZWFZ0//++NJfPEMd+Jioa2tg9qmZtD5IqGSl5eHvoEB6lnbfHkqqZNdqu6e425cLLT+X3djxgdg5JCBaN3GGU7O7XHm9EmcPBaBfRGnvnJW6XU68gQYY7CytsHThHjMmjYV1tY2GOg9WNShib1Z04PRxa0rTE3NkJmZid07t+PC+XM4FHH82weT73Ljxg106NCBe178IdPHxwehoaFcq32TJk0Ejjt79ixcXFygqKiInTt3IjQ0FLm5uahbty4mTpwo8GG1IkSegFQnDQ0NGBsbIyoqCu3bt+fKo6KiBFoLvmRubl6qrEGDBrh69apA2ZUrVwSeR0VFYfDgwVxLSVZWVqX6w8oTFRUFT09PDBo0CEBRYvL48WPY/n+wloWFBeTl5XH9+nVujnZ6ejoeP36Mdu2Kpgc6ODigsLAQqampcHZ2/u6YROl2zE30cO/EPZ8ZPBkA8OsAL6z6a4OowpIIsTE30bt7Z+55yLSiuvtlgBdW/Lke7h498PvS1Vi55A/MCJoISytrrN+yC60cnco7pVTLyMhA2KzpePP6FbS1deDRoxdmhM4p9cGIlJb6NhXDhvog+f9LKzSys8ehiOPo2Knztw+uoYS1DoiLi8tXP6h/60N806ZNS73/VUWNTkAAYPLkyQgJCYGlpSWaNGmC8PBwxMbGljvTpTzjx4+Hk5MTFi1aBE9PT5w4cUKg+wUArKyssG/fPnh4eIDH42HmzJnlttxUhpWVFfbu3YvLly9DW1sbS5YsQUpKCpeAqKurw8fHB5MnT4aOjg709fUREhICGRkZrjXF2toaAwcOhLe3NxYvXgwHBwe8ffsWp0+fhr29Pbp16/bdcQqLk3N7vM2s+FTpW/fiv72TlHBybo/k9K+3nA3wGowBXoOFE5CE69m7L3r2Ln8xPFK+tX+vF3UIYkfavg1X5INQq9v48eMREBCASZMmwc7ODsePH8ehQ4dgZWVVqfO0bt0a69atw/Lly9G4cWOcPHkSM2bMENhnyZIl0NbWRps2beDh4QFXV1c0bdr0u+9hxowZaNq0KVxdXeHi4gJDQ0P06NGj1LUdHR3RvXt3dOrUCU5OTmjQoIHAGgXh4eHw9vbGpEmTYGNjgx49egi0mhBCCBEdGV7VH5KIx6oyYIKIvezsbJiYmGDx4sXw9fX9YefNyMiApqYmnr5+D/VvTMsipRXy6c+tqhTla/znpWqlKEf1V1kZGRkw1NNCenr6N6ehfu91NDU10WnJacgrlz8mrzz5n7JwKqBjtcf5o9X4LhhpERMTg4cPH6Jly5ZIT09HWFgYAMDTk5YhJ4QQIn4oAalBFi1ahEePHkFBQQHNmjXDxYsXoaenJ+qwCCGEVICwBqGKC0pAaggHBwfcvHlT1GEQQgipIt7//6vKcZKIEhBCCCFEDFR1QKmkDkKlBIQQQggRAzQNlxBCCCGkmlELCCGEECIGaBAqIYQQQoROWF9GJy4oASGEEELEALWAEEIIIUTopG0QKiUghBBCiBiQthYQmgVDCCGEEKGjFhBCCCFEDNAgVEIIIYQIHe//j6ocJ4koASGEEELEAA1CJYQQQojQSdt3wdAgVEIIIYQIHbWAEEIIIWKAumAIIYQQIhISmktUSZW6YC5evIhBgwbB0dERr1+/BgBs2bIFly5d+qHBEUIIIdKiuAWkKg9JVOkE5N9//4WrqyuUlZURExOD3NxcAEB6ejrmzZv3wwMkhBBCpEHxINSqPCRRpROQuXPnYu3atVi3bh3k5eW5cicnJ9y6deuHBkcIIYSQmqnSY0AePXqEdu3alSrX1NREWlraj4iJEEIIkTrSNgi10i0ghoaGiI+PL1V+6dIlWFhY/JCgCCGEEGnD+46HJKp0AjJ8+HBMmDABV69eBY/Hw5s3b7Bt2zYEBgZi9OjR1REjIYQQUuMVfxdMVR6SqNJdMFOnTgWfz0fHjh2Rk5ODdu3aQVFREYGBgRg3blx1xEgIIYTUeDxe1abhSmj+UfkEhMfjYfr06Zg8eTLi4+ORlZUFW1tbqKmpVUd8hBBCCKmBqrwUu4KCAmxtbdGyZUtKPgghhJDvJKx1QC5cuAAPDw8YGxuDx+PhwIEDAtsZY5g1axaMjIygrKyMTp064cmTJwL7fPjwAQMHDoSGhga0tLTg6+uLrKysSsVR6RaQDh06fPVmz5w5U9lTEkIIIVJPWF0w2dnZaNy4MYYOHYpevXqV2v7HH39gxYoV2LRpE+rWrYuZM2fC1dUV9+/fh5KSEgBg4MCBSEpKQmRkJPLz8zFkyBCMGDEC27dvr3AclU5AmjRpIvA8Pz8fsbGxuHv3Lnx8fCp7OkIIIYQAVR5QWtljunbtiq5du5a5jTGGZcuWYcaMGfD09AQAbN68GQYGBjhw4AD69euHBw8e4Pjx47h+/TqaN28OAFi5ciXc3d2xaNEiGBsbVyiOSicgS5cuLbM8NDS00s0vhBBCCCnyvS0gGRkZAuWKiopQVFSs1LmePXuG5ORkdOrUiSvT1NREq1atEB0djX79+iE6OhpaWlpc8gEAnTp1goyMDK5evYqePXtW6FpVHgPypUGDBmHDhg0/6nSEEEKIVPneMSCmpqbQ1NTkHvPnz690DMnJyQAAAwMDgXIDAwNuW3JyMvT19QW2y8nJQUdHh9unIn7Yt+FGR0dzfUOk5pOR4UFWUr+AQISozqru1ftPog5BotUzpMkClSVpK4y+fPkSGhoa3PPKtn4IW6UTkC8HrDDGkJSUhBs3bmDmzJk/LDBCCCFEmsigat0SxcdoaGgIJCBVYWhoCABISUmBkZERV56SksKNATU0NERqaqrAcQUFBfjw4QN3fGXirrCSzTuamprQ0dGBi4sLjh49ipCQkMqejhBCCCEQ3jTcr6lbty4MDQ1x+vRpriwjIwNXr16Fo6MjAMDR0RFpaWm4efMmt8+ZM2fA5/PRqlWrCl+rUi0ghYWFGDJkCOzs7KCtrV2ZQwkhhBDyFTweUJVe2srmH1lZWQLf6fbs2TPExsZCR0cHZmZm8Pf3x9y5c2FlZcVNwzU2NkaPHj0AAA0aNICbmxuGDx+OtWvXIj8/H35+fujXr1+FZ8AAlUxAZGVl0aVLFzx48IASEEIIIeQHkqliAlLZY27cuIEOHTpwzwMCAgAAPj4+2LhxI6ZMmYLs7GyMGDECaWlpaNu2LY4fPy4wznPbtm3w8/NDx44dISMjg969e2PFihWViqPSY0AaNWqEp0+fom7dupU9lBBCCCEi5uLiAsZYudt5PB7CwsIQFhZW7j46OjqVWnSsLJUeAzJ37lwEBgbiyJEjSEpKQkZGhsCDEEIIIZUnDmNAhKnCLSBhYWGYNGkS3N3dAQA///yzwE0zxsDj8VBYWPjjoySEEEJqOGF1wYiLCicgs2fPxqhRo3D27NnqjIcQQgiRSsL6LhhxUeEEpLi/qH379tUWDCGEECKthPVdMOKiUmNAJLWfiRBCCCHipVKzYKytrb+ZhHz48OG7AiKEEEKk0feuhCppKpWAzJ49G5qamtUVCyGEECK1aAzIV/Tr16/UN+ARQggh5PvJoIpjQCCZGUiFExAa/0EIIYRUH2lrAalw19HXVk0jhBBCCKmMCreA8Pn86oyDEEIIkWq0EBkhhBBChK7o23Arn01IahcMJSCEEEKIGJC2MSCUgBBCCCFiQNq6YCR1/RJCCCGESDBqASGEEELEAO///1XlOElECQghhBAiBqStC4YSEEIIIUQMUAJCCCGEEKHj8XhVWnVcUlcqpwSEEEIIEQPS1gJCs2AIIYQQInTUAkIIIYSIAVqIjBBCCCFCJ8PjVWkp9qocIw4oASGEEELEgLSNAaEEhBBCCBEHVeyCkdB1yGgQKiGEEEKEj1pACCGEEDEgAx5kqtCcUZVjxAElIIQQQogYkLZZMNQFQyTO5UsX0L+PJ2wtTaGjKoeIwwcFth8+uB+9PNxgaaoPHVU53LkdK5pAxRDVXdXt2vwPenVujdYNjNG6gTEGev6Ei2dPAgBev3wBO1P1Mh8njuwXceTiZ+Hv8+HUugVqaavDzFgffXv3wONHj0QdlsgVD0KtykMS1bgEJDQ0FE2aNBHKtTZu3AgtLS2hXIv8Jzs7G43s7PHH0pVlbs/JzkbrNk4ImTNfyJGJP6q7qjMwMoZ/8GzsOnoBOyPOo1Wb9hjv2w/xjx7A0Lg2zt6MF3iMmTQdKqpqcO7QWdShi52LF85j1OixOH/pCo4ci0RBfj66u3dBdna2qEMTqeJpuFV5VFSdOnW4Jd9LPsaOHQsAcHFxKbVt1KhR1XK/Na4LJjAwEOPGjRN1GKQadXbtis6uXcvd/uuAQQCAxBfPhRSR5KC6qzqXzu4Cz8cHhWDXlvWIi7mGejYNoKdvILD9zPHDcO3eEyqqasIMUyIcijgu8Pzv9RthZqyPmFs30da5nYiikg7Xr19HYWEh9/zu3bvo3Lkz+vbty5UNHz4cYWFh3HMVFZVqiaXGJSBqampQU/u+P/j8/HzIy8v/oIgIITVNYWEhTh7Zj0+fstG4aatS2+/FxeDhvThMn7tYBNFJnoz0dACAtraOiCMRLWGMAalVq5bA8wULFsDS0hLt27fnylRUVGBoaFj5QCpJpF0wLi4uGDduHPz9/aGtrQ0DAwOsW7cO2dnZGDJkCNTV1VGvXj0cO3YMQNEfva+vL+rWrQtlZWXY2Nhg+fLlAuf8sguGz+cjLCwMtWvXhqKiIpo0aYLjx//Lvp8/fw4ej4ddu3ahffv2UFJSwrZt28qMd+PGjTAzM4OKigp69uyJ9+/fC2xPSEiAp6cnDAwMoKamhhYtWuDUqVMC+9SpUwdz586Ft7c31NTUYG5ujkOHDuHt27fw9PSEmpoa7O3tcePGDe6Y9+/fo3///jAxMYGKigrs7OywY8cOgfNmZmZi4MCBUFVVhZGREZYuXQoXFxf4+/tz++Tm5iIwMBAmJiZQVVVFq1atcO7cuW/+OxFCijx+cA8tbQzRzFIXc6b5Y9m67bC0rl9qv/07N8PCygZNmrcWQZSShc/nY/Ikfzi2cULDRo1EHY5IyaCKXTBVnAWTl5eHrVu3YujQoQLfqLtt2zbo6emhUaNGCA4ORk5Ozo+6RQEiHwOyadMm6Onp4dq1axg3bhxGjx6Nvn37ok2bNrh16xa6dOkCLy8v5OTkgM/no3bt2tizZw/u37+PWbNmYdq0adi9e3e551++fDkWL16MRYsWIS4uDq6urvj555/x5MkTgf2mTp2KCRMm4MGDB3B1dS11nqtXr8LX1xd+fn6IjY1Fhw4dMHfuXIF9srKy4O7ujtOnTyMmJgZubm7w8PBAYmKiwH5Lly6Fk5MTYmJi0K1bN3h5ecHb2xuDBg3CrVu3YGlpCW9vbzDGAACfP39Gs2bNEBERgbt372LEiBHw8vLCtWvXuHMGBAQgKioKhw4dQmRkJC5evIhbt24JXNfPzw/R0dHYuXMn4uLi0LdvX7i5uZWqi5Jyc3ORkZEh8CBEWtW1tMLe41HYdugsfvHyxYyJI5Hw+KHAPp8/fcLRg3vQ61dvEUUpWfzHjcW9e3exedtOUYcicsUtIFV5ACj1Wp2bm/vV6x04cABpaWkYPHgwVzZgwABs3boVZ8+eRXBwMLZs2YJBgwZVz/2y4nc5EXBxcUFhYSEuXrwIoKiFQ1NTE7169cLmzZsBAMnJyTAyMkJ0dDRaty79acLPzw/JycnYu3cvgKIWkAMHDiA2NhYAYGJigrFjx2LatGncMS1btkSLFi2wevVqPH/+HHXr1sWyZcswYcKEcmMdMGAA0tPTERERwZX169cPx48fR1paWrnHNWrUCKNGjYKfnx+AohYQZ2dnbNmyReD+Zs6cyfW5XblyBY6OjkhKSiq3Gax79+6oX78+Fi1ahMzMTOjq6mL79u3o06cPACA9PR3GxsYYPnw4li1bhsTERFhYWCAxMRHGxsbceTp16oSWLVti3rx5ZV4nNDQUs2fPLlX+POkDNDQ0yr1vYdFRlcOWnf+im4dnqW2JL56jiW09nL98A3aNmwg/ODEnaXX3+sMnUYdQyrD+HjA1r4uQBSu4ssP/7sCsyWNx+voj6OjW+srRwlXPUPzGoviP98ORwwdx6swF1KlbV9ThlJKRkQEDXU2kp6dX6+tdRkYGNDU1sebMXSirqVf6+E9ZmRjzU+nWo5CQEISGhpZ7nKurKxQUFHD48OFy9zlz5gw6duyI+Ph4WFpaVjq2rxH5GBB7e3vuZ1lZWejq6sLOzo4rMzAoGtiVmpoKAFi9ejU2bNiAxMREfPr0CXl5eeXOesnIyMCbN2/g5OQkUO7k5ITbt28LlDVv3pz7uWHDhnjx4gUAwNnZGceOHcODBw/Qs2dPgWMcHR0FunOysrIQGhqKiIgIJCUloaCgAJ8+fSrVAlLynovvr7x7NjQ0RGFhIebNm4fdu3fj9evXyMvLQ25uLjcw6OnTp8jPz0fLli25c2hqasLGxoZ7fufOHRQWFsLa2logltzcXOjq6pZZfwAQHByMgIAA7nlGRgZMTU3L3Z8QacL4fOR98Slz387N6NDZXaySD3HDGMPECeNw6OB+nDx1TiyTD0n08uVLgURJUVGx3H1fvHiBU6dOYd++fV89Z6tWRWOcamQC8uVgTx6PJ1BW3C/F5/Oxc+dOBAYGYvHixXB0dIS6ujoWLlyIq1evfnccqqqq3M9Hjx5Ffn4+AEBZWbnC5wgMDERkZCQWLVqEevXqQVlZGX369EFeXp7AfmXdX3n3DAALFy7E8uXLsWzZMtjZ2UFVVRX+/v6lzvs1WVlZkJWVxc2bNyErKyuw7WuDdhUVFb/6SywKWVlZeJYQzz1/8fwZ7tyOhbaODmqbmuHjhw949TIRyUlvAABPnjwGAOgbGMJACAOrxBnVXdUtWxCCti6dYWRiiuysLBw9uBvXoy9i7dYD3D6JzxJw82oU1mz6V3SBSgD/cWOxa+d27Nl3EGrq6khOTgZQ9MGpMq+5NU3xtNeqHAcAGhoaFW6pCQ8Ph76+Prp16/bV/Yp7E4yMjCod17eIPAGpjKioKLRp0wZjxozhyhISEsrdX0NDA8bGxoiKihIY4RsVFSXQWvAlc3PzUmUNGjQolehcuXKlVHyDBw/mWkqysrLw/Pnzr95TRURFRcHT05Prh+Pz+Xj8+DFsbW0BABYWFpCXl8f169dhZmYGoKgL5vHjx2jXrmhKm4ODAwoLC5GamgpnZ+fvjkmUYm/dwM9dO3HPZ0wNBAD0H+iN1X9vwLGIw/Ab5cttH+YzAAAwZdpMTJ0eItxgxQzVXdV9ePcW0yeOxNvUZKira8CqQSOs3XoAbdr9xO2zf9cWGBiZoE37jiKMVPz9/defAIAuHV0Ey/8Jh5fPYOEHJCZ4qNr3ylX2GD6fj/DwcPj4+EBO7r80ICEhAdu3b4e7uzt0dXURFxeHiRMnol27dgIt9z+KRCUgVlZW2Lx5M06cOIG6detiy5YtuH79Oup+pflu8uTJCAkJgaWlJZo0aYLw8HDExsaWO9OlPOPHj4eTkxMWLVoET09PnDhxQqD7pTi+ffv2wcPDAzweDzNnzuRaMb6HlZUV9u7di8uXL0NbWxtLlixBSkoKl4Coq6vDx8cHkydPho6ODvT19RESEgIZGRkuM7a2tsbAgQPh7e2NxYsXw8HBAW/fvsXp06dhb2//zSxYnLRt54IP2QXlbh/g5YMBXj5CjEhyUN1VXdiiNd/cZ8LUUEyYGlr9wUi4T/kiG3oo1iq7qFjJ4yrj1KlTSExMxNChQwXKFRQUcOrUKSxbtgzZ2dkwNTVF7969MWPGjErHVBESlYCMHDkSMTEx+PXXX8Hj8dC/f3+MGTOGm6ZblvHjxyM9PR2TJk1CamoqbG1tcejQIVhZWVXq2q1bt8a6desQEhKCWbNmoVOnTpgxYwbmzJnD7bNkyRIMHToUbdq0gZ6eHoKCgn7IrJEZM2bg6dOncHV1hYqKCkaMGIEePXog/f9z54uvPWrUKHTv3h0aGhqYMmUKXr58CSUlJW6f8PBwzJ07F5MmTcLr16+hp6eH1q1bo3v37t8dIyGEkO8njFXVu3TpgrLmn5iamuL8+fNCiKCISGfBVIfg4GBcvHgRly5dEnUoIpWdnQ0TExMsXrwYvr6+3z6ggopHa4vLLBgiPcRxFowkEcdZMOJO2LNg/j53HypVmAWTk5WJES621R7njyZRLSBfwxjD06dPcfr0aTg4OIg6HKGLiYnBw4cP0bJlS6Snp3NTej09S0+xJIQQIn7o23AlVHp6OmxtbaGgoCCw5oc0WbRoERo3boxOnTohOzsbFy9ehJ6enqjDIoQQUgFlfUlcRR+SqMa0gGhpaX1z1beazMHBATdv3hR1GIQQQqpIBlVrFZDUloQak4AQQgghkux71wGRNJSAEEIIIWJAWOuAiAtJbbkhhBBCiASjFhBCCCFEDFAXDCGEEEKEjgahEkIIIUToqAWEEEIIIUJHg1AJIYQQQqoZtYAQQgghYkDalmKnBIQQQggRAzLgQaYKHSpVOUYcUAJCCCGEiAFqASGEEEKI0PH+/19VjpNENAiVEEIIIUJHLSCEEEKIGKAuGEIIIYQIHa+Kg1AltQuGEhBCCCFEDFALCCGEEEKETtoSEBqESgghhBChoxYQQgghRAxI2zRcSkAIIYQQMSDDK3pU5ThJRAkIIYQQIgaoBYQQQgghQkeDUAkhhBBCqhm1gBBCCCFigIeqdadIaAMIJSCEEEKIOKBBqIQQQggROmkbhEpjQAghhBAxUDwItSqPigoNDQWPxxN41K9fn9v++fNnjB07Frq6ulBTU0Pv3r2RkpJSDXdLCQghhBAiFnjf8aiMhg0bIikpiXtcunSJ2zZx4kQcPnwYe/bswfnz5/HmzRv06tXre2+tTNQFQwghhEgROTk5GBoalipPT0/H+vXrsX37dvz0008AgPDwcDRo0ABXrlxB69atf2gc1AJCCCGEiAEZ8CDDq8Kjkm0gT548gbGxMSwsLDBw4EAkJiYCAG7evIn8/Hx06tSJ27d+/fowMzNDdHT0D71XgFpASBV9ziuEfF6hqMOQOGpK9CdXVYZaSqIOQaLdf5Uh6hAkTlamcOusKt0pxccBQEaGYLyKiopQVFQUKGvVqhU2btwIGxsbJCUlYfbs2XB2dsbdu3eRnJwMBQUFaGlpCRxjYGCA5OTkKkT2dfRqSAghhIiD78xATE1NBYpDQkIQGhoqUNa1a1fuZ3t7e7Rq1Qrm5ubYvXs3lJWVq3DxqqMEhBBCCBED3zsN9+XLl9DQ0ODKv2z9KIuWlhasra0RHx+Pzp07Iy8vD2lpaQKtICkpKWWOGfleNAaEEEIIqQE0NDQEHhVJQLKyspCQkAAjIyM0a9YM8vLyOH36NLf90aNHSExMhKOj4w+Pl1pACCGEEHFQxS+jq0yjSWBgIDw8PGBubo43b94gJCQEsrKy6N+/PzQ1NeHr64uAgADo6OhAQ0MD48aNg6Oj4w+fAQNQAkIIIYSIhe8dhFoRr169Qv/+/fH+/XvUqlULbdu2xZUrV1CrVi0AwNKlSyEjI4PevXsjNzcXrq6uWLNmTRWi+jZKQAghhBBxIIQMZOfOnV/drqSkhNWrV2P16tVVCKRyKAEhhBBCxAB9FwwhhBBCSDWjFhBCCCFEDFT2i+VKHieJKAEhhBBCxIAwBqGKE0pACCGEEHEgZRkIJSCEEEKIGKBBqIQQQggh1YxaQAghhBAxQINQCSGEECJ0UjYEhBIQQgghRCxIWQZCCQghhBAiBmgQKiGEEEJINaMWEEIIIUQM0CBUQgghhAidlA0BoQSEEEIIEQtSloFQAkIIIYSIAWkbhEoJCCGEECIGpG0MCM2CIYQQQojQUQsIIYQQIgakbAgIJSCEEEKIWJCyDIQSEEIIIUQM0CBUQgghhAgdDUIlhBBCCKlm1AJCCCGEiAEpGwJCCQghhBAiFqQsA6EEhBBCCBEDNAiVEEIIIcJXxUGoEpp/0CDUL7m4uMDf31/UYQgNj8fDgQMHRB1GpVyJugiffj3RtEEdmGgr4njEQYHtb1NT4D9mGJo2qANLYy0M7NMdTxOeiCha8VZYWIi5s2fBrr4lDLRV0djWCn/MnwvGmKhDEzuXL13EwL490MjKDLXU5XH08MFy9w2cMAa11OWxdvVyIUYoOcL/XIJmdTWxKGwqV/bbtAn4uX1jtKlvgI7NLBAwvD+eJTwWYZSkulECUk3OnTsHHo+HtLQ0UYdS4+TkZMO2kT1+W1j6xZ0xhqGD+iLx+TNs2LYXJ85fhUltM/Tr4Y6c7GwRRCveli7+A+vXrcWipStwLfYeZs+dj+VLFuKvNatEHZrYycnJRkM7e/y+eMVX94s4dAA3rl+FoZGxkCKTLPdu38S+7eGwqt9IoLxBoyYI/WMN9p66hlWb9oExhrHePVFYWCiiSIWP9x0PSURdMCKWl5cHBQUFUYchUX7q7IafOruVue1pwhPcun4VZy7HwKaBLQBgwZJVaGJjhgP/7sIA76HCDFXsXbtyGe7df4Zr124AAHPzOti7eydu3rgm4sjET6cubujUpezfu2JJb14jeLI/dh+IwIA+nkKKTHLkZGdhhv9wzJi/AutXLRLY1mvAEO5n49rmGDNpBvq5O+HNqxcwNbcQdqiiIWWDUKW6BSQ7Oxve3t5QU1ODkZERFi9eLLA9NzcXgYGBMDExgaqqKlq1aoVz585x21+8eAEPDw9oa2tDVVUVDRs2xNGjR/H8+XN06NABAKCtrQ0ej4fBgwcDKOri8fPzg7+/P/T09ODq6goAOH/+PFq2bAlFRUUYGRlh6tSpKCgoAABs3rwZurq6yM3NFYivR48e8PLy4p4fPHgQTZs2hZKSEiwsLDB79mzuHADw5MkTtGvXDkpKSrC1tUVkZOQPq0txkZebBwBQVFLkymRkZKCgoIhrVy6LKiyx1bJ1G1w4ewbxT4qauu/E3caV6Ch0/sYbLSmNz+djzPDBGDshAPUbNBR1OGJpwaxAtP3JFa3advjqfp9ysnFo7zaYmJrD0Ki2kKITPd53/FdR8+fPR4sWLaCurg59fX306NEDjx49EtjHxcUFPB5P4DFq1KgffbvS3QIyefJknD9/HgcPHoS+vj6mTZuGW7duoUmTJgAAPz8/3L9/Hzt37oSxsTH2798PNzc33LlzB1ZWVhg7dizy8vJw4cIFqKqq4v79+1BTU4OpqSn+/fdf9O7dG48ePYKGhgaUlZW5627atAmjR49GVFQUAOD169dwd3fH4MGDsXnzZjx8+BDDhw+HkpISQkND0bdvX4wfPx6HDh1C3759AQCpqamIiIjAyZMnAQAXL16Et7c3VqxYAWdnZyQkJGDEiBEAgJCQEPD5fPTq1QsGBga4evUq0tPTa+RYl3rWNjCpbYb5YTPx+9LVUFFRxbo1K5D05hVSU5JEHZ7YCQgMQmZGBpo3toWsrCwKCwsxc/Zc/NJ/oKhDkzgrliyEnJwcRoweJ+pQxNKJw3vx8N5tbDl4ttx9dm9ZhxULQvApJxvmFlZYveUA5KWohVgYK6GeP38eY8eORYsWLVBQUIBp06ahS5cuuH//PlRVVbn9hg8fjrCwMO65iopK5QP7BqlNQLKysrB+/Xps3boVHTt2BFCUGNSuXZRtJyYmIjw8HImJiTA2LurLDQwMxPHjxxEeHo558+YhMTERvXv3hp2dHQDAwuK/ZkIdHR0AgL6+PrS0tASubWVlhT/++IN7Pn36dJiammLVqlXg8XioX78+3rx5g6CgIMyaNQvKysoYMGAAwsPDuQRk69atMDMzg4uLCwBg9uzZmDp1Knx8fLhY5syZgylTpiAkJASnTp3Cw4cPceLECe5+5s2bh65du361nnJzcwVaXjIyMipeySIgLy+Pf7bswqRxI9GwriFkZWXh7PITfurkSgMry7Bv727s2bkd/2zciga2DXEnLhZTJwfAyMgIAwb5iDo8iXE75ib+/nMlzly6Bp6krotdjZLfvMKi2VOxZssBKCoqlbtfV89f0LrtT3iXmowt61Ziqt9gbNh78qvHkMo5fvy4wPONGzdCX18fN2/eRLt27bhyFRUVGBoaVmssUpuAJCQkIC8vD61ateLKdHR0YGNjAwC4c+cOCgsLYW1tLXBcbm4udHV1AQDjx4/H6NGjcfLkSXTq1Am9e/eGvb39N6/drFkzgecPHjyAo6OjwAuXk5MTsrKy8OrVK5iZmWH48OFo0aIFXr9+DRMTE2zcuBGDBw/mjrl9+zaioqLw22+/cecoLCzE58+fkZOTgwcPHsDU1JRLPgDA0dHxm7HOnz8fs2fP/uZ+4sS+SVNEXryOjPR05OfnQVevFrp3agv7Jk1FHZrYmTUtCBMDg9Dnl34AgIaN7PAyMRFLFv5OCUglRF++hHdvU9GkwX8fQgoLCxEybQr+XrMSt+7FizA60XtwNxYf3r/FQI//3uAKCwtx61oUdm/+G9GP3kJWVhbqGppQ19CEWV1L2Dm0gEsTc5w9cQRuP/cRYfTCI4ohIOnp6QD++9BcbNu2bdi6dSsMDQ3h4eGBmTNn/vBWEKlNQL4lKysLsrKyuHnzJmRlZQW2qampAQCGDRsGV1dXritk/vz5WLx4McaN+3oTbMlmropycHBA48aNsXnzZnTp0gX37t1DRESEQLyzZ89Gr169Sh2rpFT1Tw/BwcEICAjgnmdkZMDU1LTK5xMmDU1NAEUDU2/H3MTkaSEijkj85HzKAU9G8OVLRlYWfD5fRBFJpl/6DUL7Dh0Fy3p0Q99+AymRA9CyTXvsOh4tUDZ7yhjUsbCGzyj/Uq+xQNGMNsYY8vJyS22rsb4zA/myhVpRURGKioplHFCEz+fD398fTk5OaNTov1lJAwYMgLm5OYyNjREXF4egoCA8evQI+/btq0Jw5ZPaBMTS0hLy8vK4evUqzMzMAAAfP37E48eP0b59ezg4OKCwsBCpqalwdnYu9zympqYYNWoURo0aheDgYKxbtw7jxo3jZrZUZApZgwYN8O+//4IxxrVoREVFQV1dnesSAooSnmXLluH169fo1KmTQCLQtGlTPHr0CPXq1Sv3Gi9fvkRSUhKMjIwAAFeuXPlmbN/6BRaF7KwsPHuWwD1PfPEcd+/chraWNkxMzXD4wL/Q1dODSW1TPLx/F7OmBsKt289o/1NnEUYtnrq6d8fi3+fD1NQM9W0bIi42BqtXLMUg7yHfPljKZGVl4dnT/1oyEl88w524WGhr66C2qRl0/t8yWkxeXh76BgaoZ20j7FDFjqqaOurZ2AqUKSurQlNbB/VsbPEq8RlOHtkHR+efoKWjh9TkN9j451IoKSmhrUsXEUUtfN+7EuqXHw5DQkIQGhpa7nFjx47F3bt3cenSJYHy4vGDAGBnZwcjIyN07NgRCQkJsLS0rHR85ZHaBERNTQ2+vr6YPHkydHV1oa+vj+nTp0NGpmhikLW1NQYOHAhvb28sXrwYDg4OePv2LU6fPg17e3t069YN/v7+6Nq1K6ytrfHx40ecPXsWDRo0AACYm5uDx+PhyJEjcHd3h7KyMtdy8qUxY8Zg2bJlGDduHPz8/PDo0SOEhIQgICCAiwcoykoDAwOxbt06bN68WeAcs2bNQvfu3WFmZoY+ffpARkYGt2/fxt27dzF37lx06tQJ1tbW8PHxwcKFC5GRkYHp06dXU+1Wr9uxN9HX478XpdnTpwAA+vb3wrI1/yA1JQmzp0/Bu7cp0DcwQp9+A+E/eZqowhVrfyxZgd9mz8KkCX54+zYVhkbGGOI7AkHTZoo6NLFzO+Ymerh34p7PDJ4MAPh1gBdW/bVBVGHVCIqKSoi9Ho0dG/5ERkYadPX04dCyDTbsjYSOXi1Rhyc0PFRxEOr////y5UtoaGhw5V/78Ojn54cjR47gwoULAh90y1I8VCE+Pv6HJiA8JsUj87KysjB69Gjs27cP6urqmDRpEiIiItCkSRMsW7YM+fn5mDt3LjZv3ozXr19DT08PrVu3xuzZs2FnZ4dx48bh2LFjePXqFTQ0NODm5oalS5dyY0TmzJmDNWvWICUlBd7e3ti4cSNcXFy485d0/vx5TJ48Gbdv34aOjg58fHwwd+5cyMkJ5oje3t6IiIjAmzdvSv1ynThxAmFhYYiJiYG8vDzq16+PYcOGYfjw4QCAx48fw9fXF9euXUOdOnWwYsUKuLm5Yf/+/ejRo0eF6iwjIwOampp4+OIt1Ev8opOKUVOS2pz/u+UVULfQ90h8lyPqECROVmYG2tubIj09XeCN/Ucrfl299yy1Sq+rmRkZaFhXv0JxMsYwbtw47N+/H+fOnYOVldU3zx8VFYW2bdvi9u3bFRrnWFFSnYBIoo4dO6Jhw4ZYseLrqzFWF0pAvg8lIFVHCcj3oQSk8mpiAjJmzBhs374dBw8e5CZdAICmpiaUlZWRkJCA7du3w93dHbq6uoiLi8PEiRNRu3ZtnD9/vtKxfQ29GkqIjx8/4ty5czh37hzWrFkj6nAIIYT8YMJYB+TPP/8EAG4Jh2Lh4eEYPHgwFBQUcOrUKSxbtgzZ2dkwNTVF7969MWPGjMoH9g2UgEgIBwcHfPz4Eb///rtA1koIIaSmqP6JuN/q9DA1Nf3hLR3loQREQjx//lzUIRBCCKlGwmgBESeUgBBCCCFiQMq+i066v4yOEEIIIaJBLSCEEEKIGKAuGEIIIYQI3feuhCppKAEhhBBCxIGUDQKhBIQQQggRA1KWf9AgVEIIIYQIH7WAEEIIIWKABqESQgghROhoECohhBBChE/KBoFQAkIIIYSIASnLP2gQKiGEEEKEj1pACCGEEDFAg1AJIYQQIgJVG4QqqZ0wlIAQQgghYkDaWkBoDAghhBBChI4SEEIIIYQIHXXBEEIIIWJA2rpgKAEhhBBCxACthEoIIYQQoaMWEEIIIYQInbSthEoJCCGEECIOpCwDoVkwhBBCCBE6agEhhBBCxAANQiWEEEKI0NEgVEIIIYQInZQNAaEEhBBCCBELUpaB0CBUQgghhAgdtYAQQgghYoAGoRLyFYwxAEBWZqaII5FM/Dz6k6uq/AK+qEOQaFmZOaIOQeJkZxW9zhW/7lW3zMyMKg0ozczM+PHBCAG9GpJKyfx/4tG8kYWIIyGEEOHIzMyEpqZmtZ1fQUEBhoaGsKprWuVzGBoaQkFB4QdGVf14TFipHakR+Hw+3rx5A3V1dfDEbO5XRkYGTE1N8fLlS2hoaIg6HIlCdfd9qP6qTpzrjjGGzMxMGBsbQ0ameodMfv78GXl5eVU+XkFBAUpKSj8woupHLSCkUmRkZFC7dm1Rh/FVGhoaYvdCJimo7r4P1V/ViWvdVWfLR0lKSkoSl0B8L5oFQwghhBChowSEEEIIIUJHCQipMRQVFRESEgJFRUVRhyJxqO6+D9Vf1VHdSS8ahEoIIYQQoaMWEEIIIYQIHSUghBBCCBE6SkAIIYQQInSUgBBCCCFE6CgBIYQQUiN8/PhR1CGQSqAEhBBCiMTr27cvhg8fjqSkJFGHQiqIEhBCiMjQKgBVR3UnaPDgwTh8+DBCQkLw5s0bUYdDKoC+C4aQr+Dz+dX+JVTSqmTd5uXlITc3F+rq6iKOSjJQ3QnKy8tDt27dcPz4cXTp0gVycnKYOnUqzMzMRB0a+QpKQAgpR8kX+cuXL+Pt27cwNjaGmZkZDAwMRBydZCtZt/Pnz8e1a9dw7do1+Pr6ok2bNnBzcxNxhOKL6k4Qn8/nvobe2toakydPxoIFC6CgoIApU6bA2NhYxBGS8tBKqIR8w9SpU7Fr1y5oamoiNzcX9erVQ1BQENq2bSvq0CTe9OnTsW7dOvzxxx9QUFDA3Llzoauri507d8LExETU4Yk1qjtBgYGB2LdvH37++Wfcv38fZ86cwdChQzF79mwYGRmJOjxSFkYIKdeff/7JDA0N2cWLFxljjE2bNo2pqamxkydPijgyyXf37l1mZ2fHLly4wBhj7NKlS0xBQYFt3LiRMcZYQUGBKMMTa1R3gs6dO8e0tLTY5cuXubIDBw4wWVlZNmLECPbq1SsRRkfKQ53bhHzFtWvXMHToULRt2xYHDhzAqlWrsGjRInTu3BmfPn1CamqqqEOUWLKysgAAZ2dn7N27F25ubli+fDl8fHyQk5ODQ4cOISUlRcRRiieqO0EFBQXQ1taGubk5GGPg8/nw9PTEli1bsH79eqxYsQIvXrwQdZjkC5SAEPJ/7IveSD6fj0+fPqFFixa4ePEivLy88Mcff2DkyJEoKCjAli1bcOHCBRQWFoooYsnxZd0CQE5ODtLT07F8+XIMHz4cCxYswKhRowAAMTEx2LJlC02pBNXdl4rro2S9qKurIzExEQ8fPgSPxwOfzwcAODo6QldXFwsXLsTOnTtFEi/5ClE2vxAijh4+fMj9PGnSJKaiosKUlZXZtm3buPL379+zn376iS1YsEAUIUoUPp/P/bxz5072559/cs+HDRvGeDweCwsL48pycnJY9+7d2c8//8wKCwuFGqu4oboTVPKeMjIyWF5eHsvNzWWMMebl5cWsrKzYlStXuH1SUlLYpEmTWGRkJMvPzxd6vOTraBAqkXolZxXs2bMHK1euhL+/P3r16oVPnz6hX79+iI6Oxt27d6GoqIjs7Gz4+vri48ePuHTpEuTkaDJZeUrW7d27d+Hl5QVFRUVMmDAB/fv3x8uXLzF69GicP38es2bNQlZWFi5fvoykpCTExMRAXl5eaqdCU90JKnkvixcvxtmzZ5GRkQFTU1MsX74c6enpCA4OxoULFzBz5kxoaGhgy5YtyM7ORlRUFICirhr6exUflIAQqVbyRe3YsWOIiIjA1q1b0bBhQ0ybNg3dunXD9evXMX78eNy/fx9GRkZQV1eHrKwsLl68CHl5eRQWFnJ98qRskydPxosXL7hmcmNjY8yYMQMDBgzAu3fv8Pvvv+PcuXOoVasWrKyssHjxYsjJydEbBqjuvhQcHIz169dj/vz5UFFRwdSpU6GpqYmbN2/iyZMn2LZtGzZs2ABDQ0Po6enh6NGjkJeXB2MMPB5P1OGTkkTa/kKImJg8eTIzNDRk8+bNYzNnzmTGxsbMxcWFHTlyhNtn8+bNbOPGjezw4cPcLANq1v229evXMy0tLXbjxg32/v17lpiYyH766Sfm6OjIduzYwe2XlpYmcBzVLdXdlx4/fsyaNGnCzp07xxhj7NChQ0xTU5OtXLlSYL+UlBSWkZHBdWHV1PqQdJSAEKkXFxfHTExM2PHjx7mymJgY1rZtW+bo6CiQhJQkbVMdqyooKIi5uLgwxv4b0/Ds2TPWtGlTZmNjw7Zs2VLqmJJjH6SZtNfdl/cSFRXFDA0NGWOMHT58mKmpqXHjYjIzM9lff/3FsrOzBY6piWNhaoqa0TlIyHdQVVUFAG7kPJ/PR5MmTbB69WrExcVh0aJFOHDgALc/+3+vJXW7fF1xfSoqKuLTp0/Izc0Fj8dDfn4+6tSpg/nz5+Ply5fYvHkz/v33X4Fjpb2pnOquSPG93Lx5EwBgYWGBpk2b4rfffkP//v2xePFibvbP48ePcfLkSdy7d0/gHDVlDExNRP8yROrJyspCRkYGcXFxAMCtI2Bvb4+mTZvi7du32Lx5M/fCVpNe4H+k4jfNYsUv/B4eHrh27RqWLl0KAJCXlwdQNCDQzc0NeXl5WL9+PQoKCoQbsBihuitfREQERo8ejdTUVKipqSE/Px8zZ86Ev78/RowYAQD49OkTZsyYgfz8fDRr1kzEEZOKqnkjlAgpR8kBpyV/Njc3x5QpUzBhwgTUrl0bAwcOBFD0olanTh2MGDECEydOREREBBo2bCiy+MVZyfqMjY3Fu3fvUL9+fWhpaaF58+ZYtWoVJkyYgOzsbPTu3Rva2tpYs2YN2rVrB1dXVzg4OODSpUtwcXER7Y2IANXd1xkYGCAuLg5nz57Fr7/+im3btqFNmzaIjIxEXl4ejIyMcPDgQbx79w63bt2CjIxMjZr9U5PRLBgiFUq+IP3111+IjY1FVlYWevfujS5dukBFRQUzZ87Eb7/9hsGDB0NHRwc3btxAeno6YmJi0LdvXxQUFGD//v0ivhPxw0rMLpg2bRr27t2L9+/fw8rKCu3atcOUKVOgp6eHLVu2wN/fHyoqKmCMQU9PD1euXEFSUhJcXV2xf/9+qUvwqO4EFf+dshKLjcnIyCAoKAjR0dHYsWMHTExMkJKSglmzZiEuLg6ampqwtLTE8uXLa/TsnxpJVINPCBGFKVOmMD09PRYYGMg8PDxYixYt2NSpU7mBazt37mQeHh6sY8eObNCgQdwiR507d2ZBQUGiDF3s/fbbb8zQ0JCdPn2aMcaYj48Pq1WrFvP19WXJycmMMcYSEhLYxYsX2ZkzZ7jBgUFBQaxBgwbcPtKI6k5QSkqKwPP9+/czGxsbFhMTw5UVFhayvLw8gRkuNNtFslACQqTGhg0bmIWFBbt58yZjjLGDBw8yGRkZZmtry/z9/VlmZiZjjLGsrCzumOzsbBYcHMz09fUFVkglgh4/fsycnZ3ZgQMHGGOMnThxgqmpqbHevXsza2trNnz48FJvknfv3mVeXl5MR0dH4I1F2lDdCdqzZw/j8XgsJCSERUZGcuXdunXjZgSVpSbN/pEWlIAQqbF27VoWGhrKGGNs3759TFtbmy1btowFBAQwHR0dFhgYyDIyMrj9ExIS2KRJk1jt2rVr3Iv8j1ZQUMD27dvH3r17xy5dusQMDQ3Z2rVrGWOM9enTh2lra7MePXqwd+/eMcYYy8vLYzdu3GATJkxgd+7cEWXoIiftdVecOBT/Pz4+nq1Zs4Y5OzszGxsb1qNHDxYVFcX27dvHfv75Z+6bqSnhkHw0BoTUSKyMVQ/T09ORk5MDxhjc3d3h5eWFSZMm4eXLl2jZsiXk5eXh7++PgIAAAMDnz5/x+PFjaGtrw9TUVBS3IZbKG+D3+fNnKCkpYfz48fj06RPWrFkDeXl5TJs2DefOnUPbtm2xYMEC7ljGGAoKCriZHdKA6k5QyfrIyMiAhoYGt7JwYmIiXr9+jeDgYPB4PDx9+hRv3rzBjBkzEBISIuLIyY9AI3VIjVPyRe3Tp09gjEFFRQUaGhrQ1NTE+fPnkZmZiW7dugEAUlNT4ezsjE6dOmHYsGHceZSUlGBvby+SexBX7P+DAgFg//79+PTpE/T19dGpUycoKSkBAN6/f48PHz6gsLAQ8vLyiI+Px8iRI+Ht7c19U6mMjAx4PJ7Ev4FWBtWdoJJ/pwsXLsTJkyfx+fNnGBoaYuXKlTAzM4OZmRnOnj2La9eu4fjx4/jnn3+wbt06dOvWDc2bNxfxHZDvRfOUSI1T/KIWFhaGbt26oWPHjti7dy/XIiIrKwtFRUUcPnwYjx49QmhoKNTU1DB8+HDIyMigsLBQlOGLtZIzNry8vLBgwQJ06dIFISEhyM/PBwA0a9YMb9++RZcuXdC6dWvcvXsXgwYNAo/HE3gTljZUd4KK72XGjBn4/fff0bVrVzg5OeHVq1dwcHBAbGwsgKJ6a9WqFUJCQrB7926YmpriwYMHAP5bFJBIKNH0/BBSvVavXs2MjY1ZSEgI8/LyYjwej/3++++MsaJBpiNGjGAWFhbMyMiItWzZkuXl5THGqF+5PCX76ZOTk9lPP/3Erl+/zpKSktj27duZvLw88/f3Z4wVzURYtmwZGzt2LPPz8+NmJkjr0vVUd+V7+vQps7W1Zf/++y9X9uHDB9ajRw9mYmLCDQgvuZz6iBEjWLt27WjGSw1AXTCkRviyb11BQQHLly9Hnz59AACOjo7w8/NDQUEBpk2bhqVLlyI+Ph4fP35E27ZtISsrS+sHlKNk3aampiI1NRX29vawtbWFiooK+vfvD0VFRfTr1w+MMSxbtgwTJkwQOIe01i3VnaAvu0cVFBTw4sULmJubc9u1tbWxcuVKdO7cGevXr8f48eO5tUF4PB5kZGSgpaWFwsLCGlMv0or+9YjEYyWapv/99198+PAB27Zt45ZpBoDRo0cDAMaNGwcZGRlMnTpVYHwHvZiVr7hug4ODERERgQ8fPkBRURG+vr5o1KgRAKBXr17YuXMnBg0ahMzMTKxdu1ZgjIK01i3V3X9K/p1OmTIFaWlpWLlyJaysrLBt2zY0bdqU266npwdVVVV8/PhR4BwvXrzA0aNHsX//figqKgr9HsiPVXM6FIlUYiVmu0yfPh39+vXD+vXrceHCBZw4cQKpqancvqNHj8bq1asxbdo0bN26VeA89MVypZX8fpLt27dj586dGDFiBPz8/PDq1SssXrwYb9684fbp1asX1q1bh4SEhBrzpllVVHeCSv6dnj59GsePH8eQIUMgKyvLfd/N6tWruf1lZGQgLy8PdXV1rozH48Hc3Bx3795F06ZNhX4PpBqIsPuHkB/m5s2brGvXruzKlSssLS2NbdmyhfF4PBYcHMzevn0rsO/+/fup/7gSzp49yyZNmsQ2bNjAlZ06dYrJyckxX19f9vr16zKPo69Bp7r70r59+9jQoUO5MS+MMfbu3Tvm6+vLHBwcmKurK5s9ezZr27Yta9iwocDf6ZfrhRDJRwkIkXirVq1inp6erEePHtzS6YwxLgmZOnUqt4hTSZSEfB2fz2cJCQlMTU2N8Xg8bhG3YqdOnWLy8vJsxIgRLDExUURRiiequyIlB8/m5OSw9u3bMyUlJda9e3eB/T58+MA2btzIPDw8WLdu3diwYcO4geE1dQAuoQSE1AAbNmxgGhoazNTUtNSKpVu3bmWysrJs9OjRLC0tTTQBSrhz586xunXrss6dO3PL2Bc7ffo04/F4bMGCBSKKTrxJc909efKE+3nFihUsLi6OvXr1ivXp04eZm5uzf/75p8zj6LtdpAclIESilNf8+u+//zJDQ0M2evRo9ujRI4Ftf//9N2vTpg013X7D15r9T548yczNzZmPjw+LjY0V2Hbjxg2pf6OguhN09+5dxuPx2NatW9nkyZOZjo4O911KiYmJzMPDg7m4uLCtW7dyx3xZD/T3WvPRUuxEYpScwpeSkoLs7GxYWFhw27ds2YLg4GD07NkT48ePh5WVValzsDKWaCeCdbtp0ybEx8cjOzsbgwYNgq2tLZSUlHDixAmMHDkS7du3x6RJk0qtEluTpotWBtVdaZ8/f8aff/6JoKAgqKio4Pbt2zA3N0d+fj7k5eXx/PlzjBs3DtnZ2Rg2bBgGDBgg6pCJKIg4ASKkQkp+wgwJCWEtWrRgampqrG/fvgKLGG3evJnVrl2bTZgwgd2/f18UoUq0KVOmsFq1arHBgwezpk2bstatW7NVq1ax7OxsxljRN7VaWFgwDw8PgSZ2QnXHmGCrxdatWxmPx2M8Ho9t3ryZ217c0vHs2TPm6enJGjZsyE6cOCGSeIloUQJCxNqXzbCzZs1iBgYGbOfOnezu3bvMwcGBtWrViq1bt47bZ8uWLUxWVpYtXbpUyNFKnpKJ3dq1a5m5uTk3VuHQoUOMx+MxBwcHtnTpUpaTk8MYY+zgwYOsV69eNXamRkVR3QkqeU9JSUksLS2NPX/+nC1atIjxeDz2119/McYEB5W+fv2aBQUF0UBTKUUJCBFbz58/Z4z994J16dIlZm9vz86ePcsYY+zixYtMSUmJNW7cmDVu3JiFh4dzxx47doxe1L7Cy8uLHTp0iDFWlOR9+vSJ/f7772zJkiWMsaIxNVpaWmzp0qWsV69ezMTEhC1fvpxbGrtYTXwj/Raqu9JK3svs2bOZl5cXi46OZowxlpmZyebOnct4PB5bv349t19QUBC7c+cO95z+XqUPJSBELC1YsIDxeDx2+/ZtxljRC9yzZ8/YX3/9xQoLC1lkZCTT1dVl4eHhLDs7m5mZmbHmzZtzbwLF6EWttKSkJNazZ0+mo6PDIiMjGWNF9fv48WOWnJzMEhISmK2tLVeXd+7cYZqamszKyopt27aNMSa9AwSp7r4uKCiI6evrs127drHk5GSuPC8vj4WFhTEej8eGDx/OnJ2dWf369WvkAFxScZSAELF048YN1rNnT1a7dm1u5sCnT5/Y+/fvWV5eHuvRowebMWMG98mra9eurHbt2szf379Gv8D/KPHx8Wzo0KFMW1ubnTx5kjH2X7J26NAh1rBhQ/bs2TPGWNF00X79+rE5c+bUqE/tVUV1V7ajR48yExMTbip8YWEhS0lJYVevXuWmwIeHh7NOnTqxoUOH0jofhL6MjoinZs2a4bfffsO8efPg7u6OU6dOoUGDBlBSUkJubi6Sk5Nhb28PGRkZ8Pl81KpVC+vWrUOXLl24ry6n2S6lFc+2sLS0hJeXFz58+IBff/0VBw8ehLOzMwAgOzsbBQUFuH79OuTk5LBs2TJYW1tjxowZAIq+N0cal66nuvu6goIC1K5dG8bGxrh//z527tyJLVu2QE5ODoaGhti7dy8GDx6MX375BSoqKtwxNWn2D6kcmoZLxErJKY07duzA/fv38dtvv8HMzAwRERFo2LAh0tLS4O3tjU+fPqFJkyaIiYnBu3fvcOvWLS4hKfnNuKS0mTNnIioqCjweD5cuXYKqqip2796NTp064f379/j1118RHx+P/Px8GBoa4sqVK5CXl6fEDlR3QOlvnwaAY8eOwdfXFw4ODrh+/Tq6deuGNm3aQE9PD5MnT8Y///wDFxcXbv+aVB+kaigBIWIpMDAQe/fuxZgxY/D8+XNcvHgRHz58QEREBJo0aYIHDx5g+vTpyMzMhLq6Onbt2gV5eXlKPipg48aN8PPzw/Hjx2Fra4u4uDj8+eefiIyMxI4dO+Dq6ooPHz7g5s2byM3NRdeuXSErK0ufVkF1BwgmH48ePcKHDx9Qv359aGtrIzIyEhcvXoSdnR06dOgAPT09vH37Fp07d8aKFSvQrl07EUdPxIroen8IKdujR4+YhYUFO3LkCFd2+fJl1q1bN2ZsbMzi4uIYY4xlZGSw/Px8bswHDWirmClTpjBPT0+Bsjt37jBXV1emo6PDzp8/X+oY6qcvIs11x+fzBcZXTZs2jTVo0IAZGhqyZs2asdGjR7OUlBRue35+Pvv48SNzd3dnTk5ONaYeyI9DHxWJ2Pn06RNev34NDQ0NrszR0RETJ07E58+f0bNnT9y6dQvq6uqQk5PjxnzUlE+Y1U1bWxt3797Fhw8fuLJGjRqhd+/e+PjxI1xcXHD16lWBY2rquIXKkua6K9ldsnjxYvzzzz9YtWoVkpKS0KBBA+zevRvx8fEAgLy8PMyfPx99+/ZFamoqzp49C1lZWRQWFooqfCKGKAEhYsfKygqtWrXC8ePHkZ2dzZW7uLigUaNGyMjIQEhIiMAx1Jf8bez/va3NmzeHqqoqNmzYgHfv3nHb69Spg19//RXLly9Hs2bNRBWmWJLmupsxYwZWrlwJoOjvLCsrC+fOnUNoaCh++uknHDt2DAcPHsS8efPQpk0b5ObmQkFBAc2aNYOTkxOio6MhLy+PgoKCGpOMkR+DPjISsaOiooI2bdrgyJEjsLS0xKBBg6CgoIDMzEzo6upi48aNcHNzE3WYYq2ssTDs/4P+OnXqhJ49e2Ljxo1IS0tDnz59oKOjgxUrVsDExATjxo0DIL0zFKju/pOWloaoqCjw+XyoqalhyJAhUFNTQ1ZWFpycnHDy5En88ssvWLRoEUaMGIG8vDxs2rQJtra2cHd3h7u7O4Ci2T81oT7Ij0WDUInYKH6Rf/nyJUxNTTF06FDExMTAzMwMLVu2xLFjx8Dn83Hx4kXIysrSgNMK2LNnD2xtbdGwYUMAwIEDB3Dz5k3MmTMHM2bMwPnz5xEVFQVra2vIy8vj1q1bNW7GRlVJe90V30dqairGjh2LDx8+oH///hg2bBh69uyJBw8eIDk5GUuWLMHQoUMBAK9fv4aXlxcGDhwIX19fEd8BEXsiGntCiIDiwW379u1jxsbG7NGjR4wxxv7880/Wv39/5uzszAYMGMAtXlTTF3WqqpL1MnfuXKarq8vu3bvHGCuqW1VVVfb3339z+yQnJ7MzZ86ws2fPcoMEpXUwL9WdoJKDRi9fvszat2/PWrRowfbt28fu3bvHWrZsyezs7BhjjH3+/Jl9/PiRde3alTk7O9OAU1Ih1AJChOprrRZ79+7FkCFDsGjRIowcOVJgW05ODi1eVAlPnz7F33//jbZt26J79+64desWnJ2dsXTpUowYMaLcf4eavFBWRVHdCZo0aRISEhKQlJSEBw8ewNjYGP7+/tDS0sLkyZOhoqICPT09AEUDyK9evQp5efkaWx/kx6EEhAhNyRfu69evg8/nQ15eHk2bNgUAeHl5wdHREWPGjCn3HKyGNG9Xp+PHj8Pd3R06OjrYtm0bXF1dAQDnz59H+/btRRydeKO6E7R582b4+/vj1KlTMDc3R25uLnx8fJCfnw8fHx907twZW7ZsQX5+PkxMTDB48OAat+4JqUYibX8hUqPk+gFTpkxhpqamzMzMjCkqKjJfX1/2+vVrEUZX8wQFBTEej8eWLl3KcnNzRR2ORKG6+8+sWbOYk5MTKyws5P6GX758yVq0aMHq1avH9u7dW+oY6n4hFUUpKhGK4laLVatWYcOGDTh48CB0dXXx8uVLeHl5IS0tDUuWLIGZmZmII5Us5XUHLFiwAJmZmQgODkbdunXh6ekpgujEG9Vd+dj/WxqVlZWRm5uL3NxcKCsrIz8/H7Vr18b8+fPh6emJkJAQyMnJwdPTkzuGul1IRVEXDBEqHx8fKCsrY+3atdwLVmxsLNq1awd/f3+EhYWJOkSJUfINdPfu3Xj+/Dnk5eXh6OiI1q1bAwBGjhyJLVu2YOfOnfj5559FGa5YobqrmHv37qFJkyaYMWOGwNo7R48exV9//YVGjRphzpw5NBuNVI1I219IjVay24UxxvLy8ljHjh2Zj48PY6xo1kFxE/fixYuZlZUV+/DhA81wqaTAwECmq6vLXF1dmYGBAXNwcGBTp07lto8aNYqpq6uznTt3ijBK8UR1923h4eFMXl6eBQYGsmvXrrH4+Hjm7u4uUE/0N0uqghIQUi1KviAlJCRw3xGxadMmpqqqyk6dOsUY+y9JWbVqFXN0dJT6PvfKOnz4MDM2NmZXrlxhjDGWlpbGQkNDWYsWLVhYWBi334ABA9hPP/0kqjDFRsnfS6q7itu7dy/T19dntWvXZrVr12YODg7clPgvP2gQUlHUbkaqRXGT7LRp0/Dzzz/D1tYWU6ZMgZqaGoYOHYqxY8fi+PHj4PP5SE9Px5EjR2BiYgJ5eXkRRy5ZXrx4AV1dXTRu3BgAoKmpiTFjxqB169Y4deoUt5T9tm3bEBkZKcpQRWr8+PFITU0V6Cqguqu43r17IyYmBvv27cOWLVtw/fp1bnl1mpVGqooGoZIfqmTf+p49e7B582asWrUKcXFxOH78OBITE9G6dWt4eHige/fusLCwgKysLBQVFXH9+nXui+XoRe3riutZS0sLhYWFSEpKQt26dcEYQ61atTB06FA0bdoUt2/fRps2bQAUJYXSuHrsuXPnkJOTAx0dHYFyqrvKMTY2hrGxMfecllcn30t6/5pItSh+gb5w4QIuXbqEsLAw9OjRA7NmzcLUqVPx/v17XL58GV26dMHNmzcRGBiImTNn4ubNm/SJ6iv4fL7A8+J6dnBwwKtXr7BixQpkZ2dzdaegoAA7Ozuoq6uXeZw0cXFxwbp16yAnJ4etW7fi5cuXAKjuvhfNdiHfi2bBkB8uOTkZbdu2xdu3bzF79mz4+/tz2w4fPoxly5ZBQ0MDwcHBaNmyJbeNVk4sW8kWob/++guPHz+GmpoafH19YWZmhn379uGXX37B0KFD4e7uDnNzcwQHByMtLQ2XL1+W6jfOknX38OFD9OvXD5qamti6dStMTU2xf/9+9O3bl+qOEBGgBIRUi7i4OPTt2xfm5uZYvHgx7OzsuG1Hjx5FUFAQunfvjvnz54swSvFXstl/6tSp2LBhAxo3bozU1FR8+PABp06dgo2NDY4dO4YpU6bg48ePUFdXh4GBASIjIyEvLy/1XQcl7d27F2vXrkVhYSE2bdoEMzMzHD9+HJMnT6a6I0TIKAEh1eb27dsYMmQImjdvjgkTJnDfKgoAly9fRqtWrajF4ytKfnpPTU3F3LlzMWTIEDg4OODevXuYMmUKLl++jOjoaNSvXx/JycnIyclBTk4ObG1tISMjI7VLYn/rO4dWr14NHo+H8PBwmJubU90RIgKUgJBqFRMTg2HDhqFZs2bw9/eHra2twHbqdilt79696NOnD/d869atGD16NGxtbbF3716YmpoCAOLj4zFhwgRER0cjOjoaNjY2AueR1k/vJe/74MGDePjwIQwNDdGoUSM0a9YMwH9JCFD0fSfFdVrWOQgh1YP+wki1cnBwwD///IPY2FiEhITg2bNnAtsp+RC0fft2zJ07F3w+H8WfDYyNjeHk5IT79+9zZYwx1KtXDytWrEDbtm3RoEEDvHr1SuBc0vgGyhjj7jsoKAh+fn44duwY1q9fj/Hjx+PIkSMAgD59+mDs2LEAilbnff36NYCihBiQzrojROiEvfAIkU5Xr15lQ4YMoRUTvyE3N5f7Mq+rV68yxooWz4qKimItW7ZkVlZWLDU1lTH23wJQDx8+ZIGBgSw/P180QYuhFStWMHNzc3b58mXGGGNLlixhCgoKzNramu3Zs4fbb/fu3axjx47Mw8ODvX37VlThEiKVqAuGCA37/5gGat7+tujoaDg5OWHx4sWYOHEiGGO4fPkypk6dig8fPuDs2bPQ19cvtWYKjVsAMjMz4efnhxYtWsDPzw+HDx+Gl5cXxowZg3v37uHu3btYvnw5unfvDgDYuXMnfvvtN8yYMQO//vqriKMnRHrQuwARmuJFxij5KO3LdT5at26NOXPmICgoCMuWLQOPx0ObNm2wYMEC6OrqolOnTkhOTi61Zoo0Jh9f1p26ujpmzJgBd3d33L9/HxMmTEBYWBjmzZuHnj17IjExEV5eXjh58iQAoF+/fsjPz8e7d+9EET4hUkv6Xq2ISNEiY6WVbBE6fvw4MjIy0KRJE0yfPh3KysoICAgAAPj7+3NJiK+vLwIDA7F161ZRhi5yX9Zdeno67OzsuMHO69atQ+3ateHr6wsA0NbWhoeHBzp27IiOHTsCAJ4+fYo3b97gp59+Es1NECKlKAEhRMSK30CDg4OxcuVKGBkZ4fnz51i+fDkGDhwIHo+HgIAA8Hg8TJgwAa1bt8bu3btLzSiSRl/WnbGxMZ49e4alS5di5MiRkJeXR3x8PG7duoVWrVph/fr1aNSoEcaMGQMej4eCggJYWFggMTERWlpaor0ZQqQMJSCEiEjx+A3GGF68eIFLly4hMjISNjY22LBhA/z8/JCZmQkfHx/weDxMnjwZmZmZmDFjBrewm7ROY/5a3YWHh2P8+PHIzs5Gy5Yt0bp1a/To0QM6OjpQUFDAvn37uGOLu6wo+SBE+CgBIUQESnYdfPz4Efn5+Wjbti1atmwJWVlZBAYGQl5eHhMnTgSPx4O3tzcyMzNx4sQJTJ8+nevKksbk41t1N2nSJMjJySEgIADLli3D+PHj4e3tjeTkZAwbNgxycnJSm7gRIk5oFgwhIjR9+nRERkbi8ePHMDc3x+7duwUWFFu+fDkCAwMxdepUTJw4Edra2vSNwf/3rbpbtmwZgoKCMHnyZMydO5crp+SDEPFA0xEIEaKSMzZ27tyJ8PBweHl5YciQIYiPj8c///yDFy9ecPtMmDABoaGhOHv2rNQnH5WtO39/f8yaNQtnz55Fyc9ZlHwQIh6oBYQQETh//jx2796NVq1awdvbGwCwZs0azJ8/HwMHDsTo0aNhbm7O7V9yzIM0Jh8lUd0RUjPQGBBChCw5ORm+vr5ISUmBtbU1Vz5mzBgwxrBgwQLIysrC19cXFhYWAEBvoP9HdUdIzUFdMIQImaGhIfbt2wdjY2NERETgzp073LaxY8di2rRp+P3337mFsorRGyjVHSE1CXXBECIit2/fxpAhQ9C8eXNMmDABDRs25Lbt27cPnp6eNF6hHFR3hEg+SkAIEaGYmBgMGzYMzZo1g7+/f6nFxWjGRvmo7giRbJSAECJiMTExGDlyJMzNzfHHH3+gbt26og5JYlDdESK5aAwIISLm4OCAVatWQV1dXWD2Bvk2qjtCJBe1gBAiJopnapRc6ZNUDNUdIZKHEhBCxAhNF606qjtCJAslIIQQQggROmqrJIQQQojQUQJCCCGEEKGjBIQQQgghQkcJCCGEEEKEjhIQQgghhAgdJSCEELEzePBg9OjRg3vu4uICf39/ocdx7tw58Hg8pKWlCf3ahNR0lIAQQips8ODB4PF44PF4UFBQQL169RAWFoaCgoJqve6+ffswZ86cCu1LSQMhkkFO1AEQQiSLm5sbwsPDkZubi6NHj2Ls2LGQl5dHcHCwwH55eXlQUFD4IdfU0dH5IechhIgPagEhhFSKoqIiDA0NYW5ujtGjR6NTp044dOgQ123y22+/wdjYGDY2NgCAly9f4pdffoGWlhZ0dHTg6emJ58+fc+crLCxEQEAAtLS0oKuriylTpuDL9RG/7ILJzc1FUFAQTE1NoaioiHr16mH9+vV4/vw5OnToAADQ1tYGj8fD4MGDAQB8Ph/z589H3bp1oaysjMaNG2Pv3r0C1zl69Cisra2hrKyMDh06CMRJCPmxKAEhhHwXZWVl5OXlAQBOnz6NR48eITIyEkeOHEF+fj5cXV2hrq6OixcvIioqCmpqanBzc+OOWbx4MTZu3IgNGzbg0qVL+PDhA/bv3//Va3p7e2PHjh1YsWIFHjx4gL/++gtqamowNTXFv//+CwB49OgRkpKSsHz5cgDA/PnzsXnzZqxduxb37t3DxIkTMWjQIJw/fx5AUaLUq1cveHh4IDY2FsOGDcPUqVOrq9oIIYwQQirIx8eHeXp6MsYY4/P5LDIykikqKrLAwEDm4+PDDAwMWG5uLrf/li1bmI2NDePz+VxZbm4uU1ZWZidOnGCMMWZkZMT++OMPbnt+fj6rXbs2dx3GGGvfvj2bMGECY4yxR48eMQAsMjKyzBjPnj3LALCPHz9yZZ8/f2YqKirs8uXLAvv6+vqy/v37M8YYCw4OZra2tgLbg4KCSp2LEPJj0BgQQkilHDlyBGpqasjPzwefz8eAAQMQGhqKsWPHws7OTmDcx+3btxEfHw91dXWBc3z+/BkJCQlIT09HUlISWrVqxW2Tk5ND8+bNS3XDFIuNjYWsrCzat29f4Zjj4+ORk5ODzp07C5Tn5eXBwcEBAPDgwQOBOADA0dGxwtcghFQOJSCEkErp0KED/vzzTygoKMDY2Bhycv+9jKiqqgrsm5WVhWbNmmHbtm2lzlOrVq0qXV9ZWbnSx2RlZQEAIiIiYGJiIrBNUVGxSnEQQr4PJSCEkEpRVVVFvXr1KrRv06ZNsWvXLujr60NDQ6PMfYyMjHD16lW0a9cOAFBQUICbN2+iadOmZe5vZ2cHPp+P8+fPo1OnTqW2F7fAFBYWcmW2trZQVFREYmLi/9q5Y1fzwjiO4x/rrbMpgzrYnMnsP7CJbJIipZNIKItBCruB0VkMSp3ELhaTmSSLzUrZ7m+79Rvu/dWvnOW+X+MzPPU807tvT8+3kxPLsrRcLv9a2+/3/z4kgP/CI1QAb5PNZuX3+5VMJrXb7XS9XrXZbFStVnW73SRJtVpNw+FQruvqeDzKtu0f//AIh8PK5/MqFApyXfdrz/l8LkkKhULy+XxarVa63+96PB4yDEPNZlP1el2O4+hyuehwOGg0GslxHElSuVzW+XxWq9XS6XTSbDbTdDp99xUBvxYBAuBtPj4+tN1uZZqm0um0LMtSsVjU6/X6mog0Gg3lcjnl83nF43EZhqFUKvXjvuPxWJlMRrZtKxqNqlQq6fl8SpKCwaC63a7a7bYCgYAqlYokqdfrqdPpaDAYyLIsJRIJrddrRSIRSZJpmlosFnJdV7FYTJPJRP1+/423A/xuvs/vXnoBAAC8CRMQAADgOQIEAAB4jgABAACeI0AAAIDnCBAAAOA5AgQAAHiOAAEAAJ4jQAAAgOcIEAAA4DkCBAAAeI4AAQAAniNAAACA5/4AuBbM28zz3OAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-F1: 0.552 | Macro ROC-AUC (ovr): 0.816\n"
     ]
    }
   ],
   "source": [
    "# Step 5.E — evaluation\n",
    "# Load best (optional, but good practice)\n",
    "best_ckpt = ckpt_path  # make Step-5.E use the same, correct path\n",
    "model.load_state_dict(torch.load(best_ckpt, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "y_true, y_pred, y_prob = [], [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_dl:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        probs  = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        preds  = probs.argmax(1)\n",
    "\n",
    "        y_prob.append(probs)\n",
    "        y_pred.append(preds)\n",
    "        y_true.append(yb.numpy())\n",
    "\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_prob = np.concatenate(y_prob)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES, digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(CLASSES)), CLASSES, rotation=45)\n",
    "plt.yticks(range(len(CLASSES)), CLASSES)\n",
    "for i in range(len(CLASSES)):\n",
    "    for j in range(len(CLASSES)):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "plt.title(\"Confusion Matrix — Multiclass\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "try:\n",
    "    # macro OVR ROC-AUC (requires probabilities for all classes)\n",
    "    macro_roc_auc = roc_auc_score(y_true, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "except Exception:\n",
    "    macro_roc_auc = float(\"nan\")\n",
    "\n",
    "print(f\"Macro-F1: {macro_f1:.3f} | Macro ROC-AUC (ovr): {macro_roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "004e1ff3-831d-4b32-8a71-d3dbf7f461f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved meta: {'task': 'multiclass_damage', 'classes': ['no-damage', 'minor-damage', 'major-damage', 'destroyed'], 'img_size': 256, 'model': 'resnet18', 'checkpoint': 'resnet18_multiclass.pt', 'class_weights': [0.5319135785102844, 1.602149248123169, 1.076748013496399, 0.7891892194747925], 'val_best_acc': 0.0}\n",
      "Wrote: disaster-ai/models/cv/val_multiclass_scores.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 5.F — save meta + CSV for report\n",
    "meta = {\n",
    "    \"task\": \"multiclass_damage\",\n",
    "    \"classes\": CLASSES,\n",
    "    \"img_size\": IMG_SIZE,\n",
    "    \"model\": \"resnet18\",\n",
    "    \"checkpoint\": Path(best_ckpt).name,\n",
    "    \"class_weights\": ce_weights.detach().cpu().tolist(),\n",
    "    \"val_best_acc\": float(best)\n",
    "}\n",
    "os.makedirs(\"disaster-ai/models/cv\", exist_ok=True)\n",
    "with open(\"disaster-ai/models/cv/resnet18_xbd_multiclass_meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print(\"Saved meta:\", meta)\n",
    "\n",
    "# CSV (per-sample in val set)\n",
    "csv_path = \"disaster-ai/models/cv/val_multiclass_scores.csv\"\n",
    "import csv\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"row_index\", \"y_true\"] + [f\"p_{c}\" for c in CLASSES] + [\"y_pred\"])\n",
    "    idx = 0\n",
    "    for probs, y in zip(np.split(y_prob, len(y_true)), np.split(y_true, len(y_true))):\n",
    "        p = probs[0]\n",
    "        yt = int(y[0])\n",
    "        yp = int(p.argmax())\n",
    "        w.writerow([idx, yt] + [float(z) for z in p] + [yp])\n",
    "        idx += 1\n",
    "print(\"Wrote:\", csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "921dbd73-4fa3-403b-8116-d3506fadf38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5.G — one-image inference helper\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Use the same normalization you used inside the dataset\n",
    "_t_eval = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "def predict_image(path: str):\n",
    "    model.eval()\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    x = _t_eval(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        p = torch.softmax(model(x), dim=1).cpu().numpy()[0]\n",
    "    top = [(CLASSES[i], float(p[i])) for i in np.argsort(-p)]\n",
    "    return top\n",
    "\n",
    "# Example (put an actual post_disaster.png path)\n",
    "# predict_image(\"disaster-ai/data/xbd/tier1/images/some_image_post_disaster.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495956d-213d-479e-8209-fa0961c4f218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfm3)",
   "language": "python",
   "name": "tfm3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
