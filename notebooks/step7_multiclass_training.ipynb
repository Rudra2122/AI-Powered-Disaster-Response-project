{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab40ae1-2680-4d0f-9f7a-7f366f06a0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Train samples: 1958 | Val samples: 448\n",
      "Class counts (train): {'no-damage': 1042, 'minor-damage': 332, 'major-damage': 247, 'destroyed': 337}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zj/8fnl8j6j7s73tqw99r9fl2r00000gn/T/ipykernel_31770/4154634881.py:226: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/40] train_loss=1.2556  val_acc=0.2411  per_class: no-damage=0.000, minor-damage=0.310, major-damage=0.869, destroyed=0.500  (took 130.6s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.2411)\n",
      "[02/40] train_loss=1.1491  val_acc=0.2366  per_class: no-damage=0.000, minor-damage=0.167, major-damage=0.869, destroyed=0.548  (took 129.3s)\n",
      "[03/40] train_loss=1.0735  val_acc=0.3772  per_class: no-damage=0.188, minor-damage=0.429, major-damage=0.803, destroyed=0.631  (took 207.8s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.3772)\n",
      "[04/40] train_loss=0.9980  val_acc=0.3482  per_class: no-damage=0.146, minor-damage=0.571, major-damage=0.721, destroyed=0.595  (took 223.4s)\n",
      "[05/40] train_loss=0.9701  val_acc=0.3326  per_class: no-damage=0.115, minor-damage=0.548, major-damage=0.557, destroyed=0.738  (took 214.5s)\n",
      "[06/40] train_loss=0.9351  val_acc=0.3862  per_class: no-damage=0.195, minor-damage=0.381, major-damage=0.787, destroyed=0.690  (took 223.4s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.3862)\n",
      "[07/40] train_loss=0.8874  val_acc=0.3906  per_class: no-damage=0.215, minor-damage=0.500, major-damage=0.689, destroyed=0.667  (took 223.8s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.3906)\n",
      "[08/40] train_loss=0.8402  val_acc=0.3482  per_class: no-damage=0.153, minor-damage=0.524, major-damage=0.787, destroyed=0.548  (took 225.0s)\n",
      "[09/40] train_loss=0.8542  val_acc=0.3906  per_class: no-damage=0.222, minor-damage=0.333, major-damage=0.656, destroyed=0.750  (took 229.0s)\n",
      "[10/40] train_loss=0.8088  val_acc=0.5134  per_class: no-damage=0.464, minor-damage=0.310, major-damage=0.689, destroyed=0.643  (took 223.7s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.5134)\n",
      "[11/40] train_loss=0.7496  val_acc=0.4107  per_class: no-damage=0.276, minor-damage=0.643, major-damage=0.590, destroyed=0.583  (took 229.0s)\n",
      "[12/40] train_loss=0.7302  val_acc=0.4062  per_class: no-damage=0.280, minor-damage=0.405, major-damage=0.787, destroyed=0.524  (took 231.2s)\n",
      "[13/40] train_loss=0.6931  val_acc=0.5290  per_class: no-damage=0.467, minor-damage=0.524, major-damage=0.738, destroyed=0.571  (took 224.5s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.5290)\n",
      "[14/40] train_loss=0.6235  val_acc=0.4844  per_class: no-damage=0.414, minor-damage=0.500, major-damage=0.770, destroyed=0.488  (took 223.0s)\n",
      "[15/40] train_loss=0.6278  val_acc=0.4933  per_class: no-damage=0.425, minor-damage=0.333, major-damage=0.689, destroyed=0.643  (took 222.3s)\n",
      "[16/40] train_loss=0.6372  val_acc=0.5067  per_class: no-damage=0.418, minor-damage=0.476, major-damage=0.639, destroyed=0.702  (took 241.5s)\n",
      "[17/40] train_loss=0.5834  val_acc=0.5112  per_class: no-damage=0.460, minor-damage=0.381, major-damage=0.639, destroyed=0.643  (took 270.9s)\n",
      "[18/40] train_loss=0.5573  val_acc=0.5491  per_class: no-damage=0.536, minor-damage=0.429, major-damage=0.689, destroyed=0.548  (took 263.0s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.5491)\n",
      "[19/40] train_loss=0.5447  val_acc=0.5112  per_class: no-damage=0.448, minor-damage=0.262, major-damage=0.721, destroyed=0.679  (took 262.6s)\n",
      "[20/40] train_loss=0.5125  val_acc=0.5491  per_class: no-damage=0.510, minor-damage=0.310, major-damage=0.689, destroyed=0.690  (took 268.7s)\n",
      "[21/40] train_loss=0.4942  val_acc=0.4911  per_class: no-damage=0.410, minor-damage=0.310, major-damage=0.689, destroyed=0.690  (took 1175.7s)\n",
      "[22/40] train_loss=0.5049  val_acc=0.5692  per_class: no-damage=0.563, minor-damage=0.310, major-damage=0.770, destroyed=0.571  (took 200.5s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.5692)\n",
      "[23/40] train_loss=0.4768  val_acc=0.6004  per_class: no-damage=0.575, minor-damage=0.333, major-damage=0.787, destroyed=0.679  (took 235.6s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.6004)\n",
      "[24/40] train_loss=0.4640  val_acc=0.6339  per_class: no-damage=0.678, minor-damage=0.262, major-damage=0.721, destroyed=0.619  (took 234.4s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.6339)\n",
      "[25/40] train_loss=0.4524  val_acc=0.5960  per_class: no-damage=0.586, minor-damage=0.238, major-damage=0.754, destroyed=0.690  (took 231.8s)\n",
      "[26/40] train_loss=0.4395  val_acc=0.6362  per_class: no-damage=0.705, minor-damage=0.190, major-damage=0.770, destroyed=0.548  (took 230.8s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.6362)\n",
      "[27/40] train_loss=0.4373  val_acc=0.6228  per_class: no-damage=0.655, minor-damage=0.214, major-damage=0.721, destroyed=0.655  (took 244.2s)\n",
      "[28/40] train_loss=0.4144  val_acc=0.6362  per_class: no-damage=0.663, minor-damage=0.286, major-damage=0.721, destroyed=0.667  (took 247.2s)\n",
      "[29/40] train_loss=0.4128  val_acc=0.6094  per_class: no-damage=0.625, minor-damage=0.286, major-damage=0.689, destroyed=0.667  (took 274.1s)\n",
      "[30/40] train_loss=0.4080  val_acc=0.6228  per_class: no-damage=0.651, minor-damage=0.238, major-damage=0.721, destroyed=0.655  (took 246.4s)\n",
      "[31/40] train_loss=0.4149  val_acc=0.6205  per_class: no-damage=0.648, minor-damage=0.262, major-damage=0.721, destroyed=0.643  (took 234.6s)\n",
      "[32/40] train_loss=0.3968  val_acc=0.6183  per_class: no-damage=0.625, minor-damage=0.262, major-damage=0.754, destroyed=0.679  (took 222.5s)\n",
      "[33/40] train_loss=0.3951  val_acc=0.6049  per_class: no-damage=0.621, minor-damage=0.262, major-damage=0.705, destroyed=0.655  (took 186.7s)\n",
      "[34/40] train_loss=0.3833  val_acc=0.6250  per_class: no-damage=0.670, minor-damage=0.262, major-damage=0.705, destroyed=0.607  (took 193.3s)\n",
      "[35/40] train_loss=0.3800  val_acc=0.6138  per_class: no-damage=0.648, minor-damage=0.238, major-damage=0.738, destroyed=0.607  (took 195.9s)\n",
      "[36/40] train_loss=0.3852  val_acc=0.6429  per_class: no-damage=0.686, minor-damage=0.262, major-damage=0.738, destroyed=0.631  (took 194.8s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.6429)\n",
      "[37/40] train_loss=0.3855  val_acc=0.6496  per_class: no-damage=0.701, minor-damage=0.214, major-damage=0.721, destroyed=0.655  (took 196.5s)\n",
      "  ✅ Saved best -> checkpoints_multiclass_strong/best.pt (val_acc=0.6496)\n",
      "[38/40] train_loss=0.3789  val_acc=0.6228  per_class: no-damage=0.674, minor-damage=0.214, major-damage=0.738, destroyed=0.583  (took 198.3s)\n",
      "[39/40] train_loss=0.3773  val_acc=0.6406  per_class: no-damage=0.697, minor-damage=0.238, major-damage=0.705, destroyed=0.619  (took 196.4s)\n",
      "[40/40] train_loss=0.3766  val_acc=0.6228  per_class: no-damage=0.663, minor-damage=0.238, major-damage=0.721, destroyed=0.619  (took 196.3s)\n",
      "Training complete. Best val_acc: 0.6495535714285714\n",
      "\n",
      "Overall Validation Accuracy (TTA=4): 64.73%\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no-damage      0.852     0.705     0.771       261\n",
      "minor-damage      0.243     0.214     0.228        42\n",
      "major-damage      0.477     0.689     0.564        61\n",
      "   destroyed      0.514     0.655     0.576        84\n",
      "\n",
      "    accuracy                          0.647       448\n",
      "   macro avg      0.522     0.566     0.535       448\n",
      "weighted avg      0.680     0.647     0.656       448\n",
      "\n",
      "\n",
      "Confusion Matrix (rows=True, cols=Pred):\n",
      " [[184  18  17  42]\n",
      " [ 15   9  15   3]\n",
      " [  6   6  42   7]\n",
      " [ 11   4  14  55]]\n"
     ]
    }
   ],
   "source": [
    "# === Stronger Multiclass Trainer (Notebook-safe, fixed) ======================\n",
    "# JSONL row: {\"image_path\": \"images/xxx_post_disaster.png\", \"damage\": \"<no/minor/major/destroyed>\"}\n",
    "\n",
    "import os, json, time, random, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# ---------------- CONFIG (you can tweak) ----------------\n",
    "DATA_DIR   = Path(\"disaster-ai/data/xbd/tier1\")\n",
    "TRAIN_JL   = DATA_DIR / \"train.jsonl\"\n",
    "VAL_JL     = DATA_DIR / \"val.jsonl\"\n",
    "OUT_DIR    = Path(\"checkpoints_multiclass_strong\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_KEY    = \"image_path\"\n",
    "LABEL_KEY  = \"damage\"\n",
    "\n",
    "CLASSES    = ['no-damage','minor-damage','major-damage','destroyed']\n",
    "CLASS_TO_ID = {c:i for i,c in enumerate(CLASSES)}\n",
    "ID_TO_CLASS = {i:c for c,i in CLASS_TO_ID.items()}\n",
    "N_CLASSES  = len(CLASSES)\n",
    "\n",
    "# Model + training\n",
    "BACKBONE     = \"resnet50\"         # 'resnet18' | 'resnet50' | 'efficientnet_b0' | 'vit_b_16'\n",
    "IMG_SIZE     = 320                # 320–384 usually helps\n",
    "BATCH_SIZE   = 24                 # lower if out of memory\n",
    "EPOCHS       = 40\n",
    "BASE_LR      = 5e-4               # will warm up first few epochs\n",
    "WEIGHT_DECAY = 1e-4\n",
    "WARMUP_EPOCHS = 3                 # LR warmup\n",
    "HEAD_WARMUP_EPOCHS = 2            # freeze backbone for first K epochs\n",
    "\n",
    "# Loss mode: \"ce_ls\" (CrossEntropy with label smoothing) or \"focal\"\n",
    "LOSS_MODE    = \"ce_ls\"            # \"ce_ls\" | \"focal\"\n",
    "LABEL_SMOOTH = 0.1                # used if LOSS_MODE == \"ce_ls\"\n",
    "FOCAL_GAMMA  = 2.0                # used if LOSS_MODE == \"focal\"\n",
    "\n",
    "# Imbalance controls\n",
    "OVERSAMPLE = {                     # multiply examples for a class in training set\n",
    "    'minor-damage': 2.0,\n",
    "    # 'major-damage': 1.2,\n",
    "}\n",
    "USE_SAMPLER = True                 # keep True to use WeightedRandomSampler also\n",
    "\n",
    "# Dataloader (Notebook-safe defaults; will be overridden for CUDA)\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY  = False\n",
    "\n",
    "# TTA (test-time augmentation)\n",
    "TTA_N = 4\n",
    "\n",
    "SEED = 42\n",
    "# --------------------------------------------------------\n",
    "\n",
    "def set_seed(s=42):\n",
    "    random.seed(s); np.random.seed(s)\n",
    "    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
    "\n",
    "def read_jsonl(path: Path) -> List[Dict]:\n",
    "    assert path.exists(), f\"Missing file: {path}\"\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "def resolve_img_path(p: str | Path) -> Path:\n",
    "    p = Path(p)\n",
    "    return p if p.is_absolute() else (DATA_DIR / p)\n",
    "\n",
    "class ImgDS(Dataset):\n",
    "    def __init__(self, rows: List[Dict], transform=None):\n",
    "        self.rows = rows\n",
    "        self.t = transform or (lambda x: x)\n",
    "\n",
    "    def __len__(self): return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        r = self.rows[i]\n",
    "        img_path = resolve_img_path(r[IMG_KEY])\n",
    "        try:\n",
    "            y = CLASS_TO_ID[r[LABEL_KEY]]\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Row {i}: bad label '{r.get(LABEL_KEY)}'. Expected {list(CLASSES)}\")\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Row {i}: missing image -> {img_path}\")\n",
    "        except UnidentifiedImageError:\n",
    "            raise UnidentifiedImageError(f\"Row {i}: unreadable image -> {img_path}\")\n",
    "        return self.t(img), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "def get_train_tf():\n",
    "    return T.Compose([\n",
    "        T.Resize(int(IMG_SIZE*1.2)),\n",
    "        T.RandomResizedCrop(IMG_SIZE, scale=(0.5, 1.0), ratio=(0.75, 1.33)),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomVerticalFlip(p=0.2),\n",
    "        T.RandomRotation(degrees=10),\n",
    "        T.RandomApply([T.ColorJitter(0.4,0.4,0.4,0.1)], p=0.7),\n",
    "        T.RandomGrayscale(p=0.1),\n",
    "        T.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "    ])\n",
    "\n",
    "def get_val_tf():\n",
    "    return T.Compose([\n",
    "        T.Resize(int(IMG_SIZE*1.2)),\n",
    "        T.CenterCrop(IMG_SIZE),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "    ])\n",
    "\n",
    "def build_model(backbone: str, n_classes: int) -> nn.Module:\n",
    "    if backbone == \"resnet18\":\n",
    "        m = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        m.fc = nn.Linear(m.fc.in_features, n_classes)\n",
    "    elif backbone == \"resnet50\":\n",
    "        m = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        m.fc = nn.Linear(m.fc.in_features, n_classes)\n",
    "    elif backbone == \"efficientnet_b0\":\n",
    "        m = torchvision.models.efficientnet_b0(weights=torchvision.models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        m.classifier[1] = nn.Linear(m.classifier[1].in_features, n_classes)\n",
    "    elif backbone == \"vit_b_16\":\n",
    "        m = torchvision.models.vit_b_16(weights=torchvision.models.ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "        m.heads.head = nn.Linear(m.heads.head.in_features, n_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone: {backbone}\")\n",
    "    return m\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2.0, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.weight, self.gamma, self.reduction = weight, gamma, reduction\n",
    "    def forward(self, logits, target):\n",
    "        ce = nn.functional.cross_entropy(logits, target, weight=self.weight, reduction=\"none\")\n",
    "        with torch.no_grad():\n",
    "            pt = torch.softmax(logits, dim=1).gather(1, target.unsqueeze(1)).squeeze(1).clamp_(1e-6, 1-1e-6)\n",
    "        loss = ((1-pt)**self.gamma) * ce\n",
    "        return loss.mean() if self.reduction==\"mean\" else loss.sum()\n",
    "\n",
    "def make_oversampled_rows(rows: List[Dict], factors: Dict[str,float]) -> List[Dict]:\n",
    "    out = []\n",
    "    for r in rows:\n",
    "        out.append(r)\n",
    "        f = float(factors.get(r[LABEL_KEY], 1.0))\n",
    "        k = max(0, int(round(f - 1.0)))\n",
    "        for _ in range(k):\n",
    "            out.append(r.copy())\n",
    "    random.shuffle(out)\n",
    "    return out\n",
    "\n",
    "def class_counts(rows: List[Dict]) -> Dict[str,int]:\n",
    "    c = {k:0 for k in CLASSES}\n",
    "    for r in rows: c[r[LABEL_KEY]] += 1\n",
    "    return c\n",
    "\n",
    "def pick_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\"), True, True   # device, use_amp, pin_memory\n",
    "    if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\"), False, False\n",
    "    return torch.device(\"cpu\"), False, False\n",
    "\n",
    "def train_and_eval():\n",
    "    set_seed(SEED)\n",
    "    device, use_amp, pin_memory = pick_device()\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    tr_rows = read_jsonl(TRAIN_JL)\n",
    "    va_rows = read_jsonl(VAL_JL)\n",
    "\n",
    "    if OVERSAMPLE:\n",
    "        tr_rows = make_oversampled_rows(tr_rows, OVERSAMPLE)\n",
    "\n",
    "    print(f\"Train samples: {len(tr_rows)} | Val samples: {len(va_rows)}\")\n",
    "    print(\"Class counts (train):\", class_counts(tr_rows))\n",
    "\n",
    "    ds_tr = ImgDS(tr_rows, get_train_tf())\n",
    "    ds_va = ImgDS(va_rows, get_val_tf())\n",
    "\n",
    "    if USE_SAMPLER:\n",
    "        counts = np.array([class_counts(tr_rows)[c] for c in CLASSES], dtype=float)\n",
    "        inv = (counts.sum() / np.maximum(counts, 1.0)).astype(float)\n",
    "        sample_w = [inv[CLASS_TO_ID[r[LABEL_KEY]]] for r in tr_rows]\n",
    "        sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n",
    "        shuffle_flag = False\n",
    "    else:\n",
    "        sampler = None\n",
    "        shuffle_flag = True\n",
    "\n",
    "    persistent = (NUM_WORKERS > 0)\n",
    "    loader_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, sampler=sampler,\n",
    "                           shuffle=shuffle_flag, num_workers=NUM_WORKERS,\n",
    "                           pin_memory=pin_memory, persistent_workers=persistent)\n",
    "    loader_va = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=pin_memory,\n",
    "                           persistent_workers=persistent)\n",
    "\n",
    "    model = build_model(BACKBONE, N_CLASSES).to(device)\n",
    "\n",
    "    counts = np.array([class_counts(tr_rows)[c] for c in CLASSES], dtype=float)\n",
    "    inv = (counts.sum() / np.maximum(counts, 1.0)).astype(float)\n",
    "    class_w = torch.tensor(inv, dtype=torch.float, device=device)\n",
    "\n",
    "    if LOSS_MODE == \"focal\":\n",
    "        loss_fn = FocalLoss(weight=class_w, gamma=FOCAL_GAMMA)\n",
    "    else:\n",
    "        loss_fn = nn.CrossEntropyLoss(weight=class_w if class_w.sum() > 0 else None,\n",
    "                                      label_smoothing=LABEL_SMOOTH)\n",
    "\n",
    "    opt = optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    # Freeze backbone for head warmup\n",
    "    for p in model.parameters(): p.requires_grad = True\n",
    "    def is_head(name): return (\"fc\" in name) or (\"classifier.1\" in name) or (\"heads.head\" in name)\n",
    "    for name, p in model.named_parameters():\n",
    "        if not is_head(name): p.requires_grad = False\n",
    "\n",
    "    best_acc = -1.0\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        # LR warmup\n",
    "        if epoch <= WARMUP_EPOCHS:\n",
    "            warm_lr = 1e-4 + (BASE_LR-1e-4) * (epoch / max(1,WARMUP_EPOCHS))\n",
    "            for g in opt.param_groups: g[\"lr\"] = warm_lr\n",
    "\n",
    "        # Unfreeze backbone after head warmup\n",
    "        if epoch == HEAD_WARMUP_EPOCHS + 1:\n",
    "            for name, p in model.named_parameters():\n",
    "                p.requires_grad = True\n",
    "            for g in opt.param_groups: g[\"lr\"] = min(g[\"lr\"], BASE_LR)\n",
    "\n",
    "        model.train()\n",
    "        t0 = time.time()\n",
    "        running, seen = 0.0, 0\n",
    "\n",
    "        for xb, yb in loader_tr:\n",
    "            xb, yb = xb.to(device, non_blocking=pin_memory), yb.to(device, non_blocking=pin_memory)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            if use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(xb)\n",
    "                    loss = loss_fn(logits, yb)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt); scaler.update()\n",
    "            else:\n",
    "                logits = model(xb)\n",
    "                loss = loss_fn(logits, yb)\n",
    "                loss.backward(); opt.step()\n",
    "\n",
    "            running += float(loss.detach().item()) * xb.size(0)\n",
    "            seen += xb.size(0)\n",
    "\n",
    "        if epoch > WARMUP_EPOCHS:\n",
    "            scheduler.step()\n",
    "        train_loss = running / max(1, seen)\n",
    "\n",
    "        # ----- Validation -----\n",
    "        model.eval()\n",
    "        preds, tgts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in loader_va:\n",
    "                xb = xb.to(device, non_blocking=pin_memory)\n",
    "                logits = model(xb)\n",
    "                pred = logits.argmax(1).cpu()\n",
    "                preds.append(pred); tgts.append(yb)\n",
    "        preds = torch.cat(preds).numpy()\n",
    "        tgts  = torch.cat(tgts).numpy()\n",
    "        acc = (preds == tgts).mean()\n",
    "\n",
    "        # per-class acc (FIXED: use np.diag on numpy cm)\n",
    "        cm = confusion_matrix(tgts, preds, labels=list(range(N_CLASSES)))\n",
    "        per_class = (np.diag(cm) / np.maximum(cm.sum(axis=1), 1)).tolist()\n",
    "        msg = \", \".join(f\"{ID_TO_CLASS[i]}={per_class[i]:.3f}\" for i in range(N_CLASSES))\n",
    "        print(f\"[{epoch:02d}/{EPOCHS}] train_loss={train_loss:.4f}  val_acc={acc:.4f}  \"\n",
    "              f\"per_class: {msg}  (took {time.time()-t0:.1f}s)\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save({\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"backbone\": BACKBONE,\n",
    "                \"classes\": CLASSES,\n",
    "                \"img_size\": IMG_SIZE,\n",
    "                \"acc\": float(best_acc),\n",
    "            }, OUT_DIR / \"best.pt\")\n",
    "            print(f\"  ✅ Saved best -> {OUT_DIR/'best.pt'} (val_acc={best_acc:.4f})\")\n",
    "\n",
    "    # save final weights only\n",
    "    torch.save(model.state_dict(), OUT_DIR / \"last_weights_only.pt\")\n",
    "    print(\"Training complete. Best val_acc:\", best_acc)\n",
    "    return model\n",
    "\n",
    "# ---------- TTA predict + Evaluation helpers ----------\n",
    "\n",
    "def build_infer_pipeline(ckpt_dir: Path = OUT_DIR):\n",
    "    ckpt_path = ckpt_dir / \"best.pt\"\n",
    "    if not ckpt_path.exists():\n",
    "        alt = ckpt_dir / \"last_weights_only.pt\"\n",
    "        assert alt.exists(), f\"No checkpoints found in {ckpt_dir}\"\n",
    "        raise RuntimeError(\"best.pt not found; re-run training to create it.\")\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    classes = ckpt.get(\"classes\", CLASSES)\n",
    "    img_size = ckpt.get(\"img_size\", IMG_SIZE)\n",
    "    backbone = ckpt.get(\"backbone\", BACKBONE)\n",
    "\n",
    "    model = build_model(backbone, len(classes))\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    model.eval()\n",
    "\n",
    "    base_tf = T.Compose([\n",
    "        T.Resize(int(img_size*1.2)),\n",
    "        T.CenterCrop(img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "    ])\n",
    "    return model, base_tf, classes\n",
    "\n",
    "def predict_one_tta(model, base_tf, classes, img_path: Path, tta_n: int = 4):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    tfs = [base_tf]\n",
    "    if tta_n >= 2: tfs.append(T.Compose([T.RandomHorizontalFlip(p=1.0), *base_tf.transforms]))\n",
    "    if tta_n >= 3: tfs.append(T.Compose([T.RandomVerticalFlip(p=1.0), *base_tf.transforms]))\n",
    "    if tta_n >= 4: tfs.append(T.Compose([T.RandomRotation(10), *base_tf.transforms]))\n",
    "\n",
    "    probs_sum = torch.zeros(len(classes))\n",
    "    with torch.no_grad():\n",
    "        for tf in tfs[:tta_n]:\n",
    "            x = tf(img).unsqueeze(0)\n",
    "            logits = model(x)\n",
    "            probs_sum += torch.softmax(logits, dim=1).squeeze(0)\n",
    "    probs = probs_sum / len(tfs[:tta_n])\n",
    "    top = int(probs.argmax().item())\n",
    "    return classes[top], float(probs[top])\n",
    "\n",
    "def eval_on_val_with_tta(tta_n: int = TTA_N):\n",
    "    model, base_tf, classes = build_infer_pipeline(OUT_DIR)\n",
    "    with open(VAL_JL, \"r\") as f:\n",
    "        rows = [json.loads(line) for line in f]\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    for r in rows:\n",
    "        p = resolve_img_path(r[IMG_KEY])\n",
    "        pred, _ = predict_one_tta(model, base_tf, classes, p, tta_n=tta_n)\n",
    "        y_pred.append(pred); y_true.append(r[LABEL_KEY])\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\nOverall Validation Accuracy (TTA={tta_n}): {acc*100:.2f}%\\n\")\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_true, y_pred, labels=CLASSES, digits=3))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=CLASSES)\n",
    "    print(\"\\nConfusion Matrix (rows=True, cols=Pred):\\n\", cm)\n",
    "\n",
    "# ======================= RUN TRAINING =======================\n",
    "model = train_and_eval()\n",
    "# After training, evaluate with TTA (increase tta_n to 4 or 8 for a small boost)\n",
    "eval_on_val_with_tta(tta_n=TTA_N)\n",
    "# ================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c41e9bf-4e8c-4596-a7d1-1f84e369cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "      <th>conf</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/socal-fire_0...</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/socal-fire_0...</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ma...</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/santa-rosa-w...</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ha...</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ha...</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-fl...</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>0.9433</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ha...</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>0.9399</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-fl...</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-fl...</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>0.9355</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ma...</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ha...</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/socal-fire_0...</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/socal-fire_0...</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ma...</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ma...</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ma...</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ha...</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>0.9177</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/midwest-floo...</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>0.9094</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/santa-rosa-w...</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ma...</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-mi...</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/midwest-floo...</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>0.8901</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/hurricane-ma...</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>minor-damage</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>disaster-ai/data/xbd/tier1/images/socal-fire_0...</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>0.8714</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path          true  \\\n",
       "395  disaster-ai/data/xbd/tier1/images/socal-fire_0...     no-damage   \n",
       "165  disaster-ai/data/xbd/tier1/images/socal-fire_0...     no-damage   \n",
       "385  disaster-ai/data/xbd/tier1/images/hurricane-ma...  major-damage   \n",
       "265  disaster-ai/data/xbd/tier1/images/santa-rosa-w...  minor-damage   \n",
       "252  disaster-ai/data/xbd/tier1/images/hurricane-ha...     destroyed   \n",
       "415  disaster-ai/data/xbd/tier1/images/hurricane-ha...  minor-damage   \n",
       "375  disaster-ai/data/xbd/tier1/images/hurricane-fl...  minor-damage   \n",
       "350  disaster-ai/data/xbd/tier1/images/hurricane-ha...     destroyed   \n",
       "281  disaster-ai/data/xbd/tier1/images/hurricane-fl...     destroyed   \n",
       "377  disaster-ai/data/xbd/tier1/images/hurricane-fl...  minor-damage   \n",
       "211  disaster-ai/data/xbd/tier1/images/hurricane-ma...  minor-damage   \n",
       "253  disaster-ai/data/xbd/tier1/images/hurricane-ha...  minor-damage   \n",
       "325  disaster-ai/data/xbd/tier1/images/socal-fire_0...  major-damage   \n",
       "114  disaster-ai/data/xbd/tier1/images/socal-fire_0...     no-damage   \n",
       "78   disaster-ai/data/xbd/tier1/images/hurricane-ma...  major-damage   \n",
       "1    disaster-ai/data/xbd/tier1/images/hurricane-ma...     destroyed   \n",
       "58   disaster-ai/data/xbd/tier1/images/hurricane-ma...     no-damage   \n",
       "164  disaster-ai/data/xbd/tier1/images/hurricane-ha...     destroyed   \n",
       "201  disaster-ai/data/xbd/tier1/images/midwest-floo...     no-damage   \n",
       "218  disaster-ai/data/xbd/tier1/images/santa-rosa-w...     no-damage   \n",
       "134  disaster-ai/data/xbd/tier1/images/hurricane-ma...     destroyed   \n",
       "148  disaster-ai/data/xbd/tier1/images/hurricane-mi...  minor-damage   \n",
       "233  disaster-ai/data/xbd/tier1/images/midwest-floo...  minor-damage   \n",
       "138  disaster-ai/data/xbd/tier1/images/hurricane-ma...  major-damage   \n",
       "22   disaster-ai/data/xbd/tier1/images/socal-fire_0...     no-damage   \n",
       "\n",
       "             pred    conf  is_correct  \n",
       "395     destroyed  0.9703       False  \n",
       "165     destroyed  0.9684       False  \n",
       "385  minor-damage  0.9633       False  \n",
       "265     destroyed  0.9526       False  \n",
       "252  major-damage  0.9525       False  \n",
       "415  major-damage  0.9459       False  \n",
       "375  major-damage  0.9433       False  \n",
       "350  major-damage  0.9399       False  \n",
       "281  major-damage  0.9387       False  \n",
       "377  major-damage  0.9355       False  \n",
       "211     destroyed  0.9347       False  \n",
       "253  major-damage  0.9333       False  \n",
       "325     destroyed  0.9330       False  \n",
       "114     destroyed  0.9244       False  \n",
       "78      destroyed  0.9232       False  \n",
       "1    minor-damage  0.9210       False  \n",
       "58   minor-damage  0.9188       False  \n",
       "164  major-damage  0.9177       False  \n",
       "201  major-damage  0.9094       False  \n",
       "218     destroyed  0.9035       False  \n",
       "134  minor-damage  0.9012       False  \n",
       "148     no-damage  0.9004       False  \n",
       "233     no-damage  0.8901       False  \n",
       "138  minor-damage  0.8832       False  \n",
       "22      destroyed  0.8714       False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: val_mistakes_top.csv\n"
     ]
    }
   ],
   "source": [
    "# Inspect where it's going wrong\n",
    "import json, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "VAL_JL = Path(\"disaster-ai/data/xbd/tier1/val.jsonl\")\n",
    "ckpt_dir = Path(\"checkpoints_multiclass_strong\")\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import torch, numpy as np\n",
    "\n",
    "# Reuse the helpers from the training cell if they still exist:\n",
    "# resolve_img_path, build_infer_pipeline, predict_one_tta, CLASSES\n",
    "\n",
    "model, base_tf, classes = build_infer_pipeline(ckpt_dir)\n",
    "rows = [json.loads(l) for l in open(VAL_JL, \"r\")]\n",
    "records = []\n",
    "for r in rows:\n",
    "    p = resolve_img_path(r[\"image_path\"])\n",
    "    pred, prob = predict_one_tta(model, base_tf, classes, p, tta_n=4)\n",
    "    records.append({\n",
    "        \"image_path\": str(p),\n",
    "        \"true\": r[\"damage\"],\n",
    "        \"pred\": pred,\n",
    "        \"conf\": round(prob, 4),\n",
    "        \"is_correct\": pred == r[\"damage\"]\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "mistakes = df[~df[\"is_correct\"]].sort_values(\"conf\", ascending=False)\n",
    "display(mistakes.head(25))\n",
    "mistakes.to_csv(\"val_mistakes_top.csv\", index=False)\n",
    "print(\"Saved:\", \"val_mistakes_top.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7577860-70c4-4364-966d-5b62c5511ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FT 01/8] train_loss=0.1565  val_acc=0.6942  (took 172.3s)\n",
      "  ✅ Saved new best.pt 0.6941964030265808\n",
      "[FT 02/8] train_loss=0.0996  val_acc=0.6875  (took 172.5s)\n",
      "[FT 03/8] train_loss=0.1097  val_acc=0.6696  (took 172.0s)\n",
      "[FT 04/8] train_loss=0.1178  val_acc=0.6830  (took 179.0s)\n",
      "[FT 05/8] train_loss=0.0831  val_acc=0.7165  (took 183.5s)\n",
      "  ✅ Saved new best.pt 0.7165178656578064\n",
      "[FT 06/8] train_loss=0.0885  val_acc=0.6920  (took 194.9s)\n",
      "[FT 07/8] train_loss=0.0772  val_acc=0.6987  (took 192.7s)\n",
      "[FT 08/8] train_loss=0.0925  val_acc=0.6808  (took 203.0s)\n"
     ]
    }
   ],
   "source": [
    "# Low-LR fine-tuning for 8 more epochs from best.pt\n",
    "import torch, json, time\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# Reuse helper funcs from earlier cell: build_model, get_train_tf, get_val_tf,\n",
    "# read_jsonl, resolve_img_path, ImgDS, CLASSES, N_CLASSES, DATA_DIR, TRAIN_JL, VAL_JL\n",
    "\n",
    "ckpt_dir = Path(\"checkpoints_multiclass_strong\")\n",
    "ckpt = torch.load(ckpt_dir/\"best.pt\", map_location=\"cpu\")\n",
    "\n",
    "model = build_model(ckpt[\"backbone\"], N_CLASSES)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.train()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() else \"cpu\"))\n",
    "model.to(device)\n",
    "\n",
    "# Datasets/loaders\n",
    "tr_rows = read_jsonl(TRAIN_JL)\n",
    "va_rows = read_jsonl(VAL_JL)\n",
    "ds_tr = ImgDS(tr_rows, get_train_tf())\n",
    "ds_va = ImgDS(va_rows, get_val_tf())\n",
    "\n",
    "loader_tr = DataLoader(ds_tr, batch_size=24, shuffle=True, num_workers=0)\n",
    "loader_va = DataLoader(ds_va, batch_size=24, shuffle=False, num_workers=0)\n",
    "\n",
    "# Very small LR; unfreeze everything\n",
    "for p in model.parameters(): p.requires_grad = True\n",
    "opt = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=5e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "best_acc = ckpt.get(\"acc\", 0.0)\n",
    "EPOCHS = 8\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time(); run, seen = 0.0, 0\n",
    "    for xb, yb in loader_tr:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward(); opt.step()\n",
    "        run += loss.item() * xb.size(0); seen += xb.size(0)\n",
    "    tr_loss = run/max(1,seen)\n",
    "\n",
    "    # val\n",
    "    model.eval()\n",
    "    preds, tgts = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader_va:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            preds.append(logits.argmax(1).cpu()); tgts.append(yb)\n",
    "    import torch as _t\n",
    "    acc = (_t.cat(preds) == _t.cat(tgts)).float().mean().item()\n",
    "    model.train()\n",
    "    print(f\"[FT {epoch:02d}/{EPOCHS}] train_loss={tr_loss:.4f}  val_acc={acc:.4f}  (took {time.time()-t0:.1f}s)\")\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save({\"model_state\": model.state_dict(),\n",
    "                    \"backbone\": ckpt[\"backbone\"],\n",
    "                    \"classes\": ckpt[\"classes\"],\n",
    "                    \"img_size\": ckpt[\"img_size\"],\n",
    "                    \"acc\": best_acc}, ckpt_dir/\"best.pt\")\n",
    "        print(\"  ✅ Saved new best.pt\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67c6edc7-25bf-4661-b698-4fb04749e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_MODE = \"focal\"         # change in your strong trainer cell\n",
    "FOCAL_GAMMA = 2.0           # keep\n",
    "OVERSAMPLE = {\n",
    "    \"minor-damage\": 3.0,    # try 3x or even 4x\n",
    "    \"major-damage\": 1.3\n",
    "}\n",
    "EPOCHS = 20                  # you can do a shorter focused run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "230667db-3aa2-4780-9c70-6edca038574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Validation Accuracy (TTA=8): 72.54%\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no-damage      0.785     0.897     0.837       261\n",
      "minor-damage      0.409     0.214     0.281        42\n",
      "major-damage      0.636     0.574     0.603        61\n",
      "   destroyed      0.644     0.560     0.599        84\n",
      "\n",
      "    accuracy                          0.725       448\n",
      "   macro avg      0.619     0.561     0.580       448\n",
      "weighted avg      0.703     0.725     0.709       448\n",
      "\n",
      "\n",
      "Confusion Matrix (rows=True, cols=Pred):\n",
      " [[234   7   2  18]\n",
      " [ 23   9   8   2]\n",
      " [ 18   2  35   6]\n",
      " [ 23   4  10  47]]\n"
     ]
    }
   ],
   "source": [
    "eval_on_val_with_tta(tta_n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef2f74e1-fb70-487d-a803-710a3999b966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweaked bias for 'minor-damage' and saved to best.pt. Re-run eval:\n",
      "\n",
      "Overall Validation Accuracy (TTA=4): 72.77%\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no-damage      0.783     0.900     0.838       261\n",
      "minor-damage      0.450     0.214     0.290        42\n",
      "major-damage      0.625     0.574     0.598        61\n",
      "   destroyed      0.653     0.560     0.603        84\n",
      "\n",
      "    accuracy                          0.728       448\n",
      "   macro avg      0.628     0.562     0.582       448\n",
      "weighted avg      0.706     0.728     0.710       448\n",
      "\n",
      "\n",
      "Confusion Matrix (rows=True, cols=Pred):\n",
      " [[235   6   2  18]\n",
      " [ 23   9   8   2]\n",
      " [ 19   2  35   5]\n",
      " [ 23   3  11  47]]\n"
     ]
    }
   ],
   "source": [
    "# Bias tweak on the classification layer to help minor-damage recall\n",
    "import torch\n",
    "\n",
    "ckpt_dir = Path(\"checkpoints_multiclass_strong\")\n",
    "ckpt = torch.load(ckpt_dir/\"best.pt\", map_location=\"cpu\")\n",
    "model = build_model(ckpt[\"backbone\"], len(ckpt[\"classes\"]))\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "\n",
    "# Identify the class index for 'minor-damage'\n",
    "minor_idx = CLASSES.index(\"minor-damage\")\n",
    "\n",
    "# Small bias lift (adjust 0.05–0.20)\n",
    "with torch.no_grad():\n",
    "    if hasattr(model, \"fc\"):            # resnets\n",
    "        model.fc.bias[minor_idx] += 0.10\n",
    "    elif hasattr(model, \"classifier\"):   # efficientnet\n",
    "        model.classifier[1].bias[minor_idx] += 0.10\n",
    "    elif hasattr(model, \"heads\") and hasattr(model.heads, \"head\"):  # ViT\n",
    "        model.heads.head.bias[minor_idx] += 0.10\n",
    "\n",
    "torch.save({\"model_state\": model.state_dict(),\n",
    "            \"backbone\": ckpt[\"backbone\"],\n",
    "            \"classes\": ckpt[\"classes\"],\n",
    "            \"img_size\": ckpt[\"img_size\"],\n",
    "            \"acc\": ckpt.get(\"acc\", 0.0)}, ckpt_dir/\"best.pt\")\n",
    "\n",
    "print(\"Tweaked bias for 'minor-damage' and saved to best.pt. Re-run eval:\")\n",
    "eval_on_val_with_tta(tta_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a31d4a-fa2b-42b1-8872-273476868169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved val_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Dump validation predictions to CSV (submission-style artifact)\n",
    "import json, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "VAL_JL = Path(\"disaster-ai/data/xbd/tier1/val.jsonl\")\n",
    "ckpt_dir = Path(\"checkpoints_multiclass_strong\")\n",
    "\n",
    "model, base_tf, classes = build_infer_pipeline(ckpt_dir)\n",
    "rows = [json.loads(l) for l in open(VAL_JL, \"r\")]\n",
    "\n",
    "recs = []\n",
    "for r in rows:\n",
    "    p = resolve_img_path(r[\"image_path\"])\n",
    "    pred, prob = predict_one_tta(model, base_tf, classes, p, tta_n=4)\n",
    "    recs.append({\"image_path\": str(p), \"true\": r[\"damage\"], \"pred\": pred, \"conf\": round(prob, 4)})\n",
    "\n",
    "pd.DataFrame(recs).to_csv(\"val_predictions.csv\", index=False)\n",
    "print(\"Saved val_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad33e90-c258-41ed-a249-0191b58164b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfm3)",
   "language": "python",
   "name": "tfm3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
